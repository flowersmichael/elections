{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3710jvsc74a57bd0c10d354e963c3ef3cfe26ce7f2c15db051cec7895d853c3c04a448c95c5a7793",
   "display_name": "Python 3.7.10 64-bit ('tf': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "c10d354e963c3ef3cfe26ce7f2c15db051cec7895d853c3c04a448c95c5a7793"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import matplotlib.colors as mcolors\n",
    "import pandas as pd \n",
    "import plotly as py\n",
    "import math\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from itertools import cycle, islice\n",
    "from sklearn.linear_model import LinearRegression, BayesianRidge\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import datetime\n",
    "import operator \n",
    "from simple_colors import *\n",
    "import colorama\n",
    "from colorama import Fore\n",
    "plt.style.use('fivethirtyeight')\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('retina')\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "import plotly.express as px\n",
    "import csv\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "import sys\n",
    "import glob\n",
    "import os.path\n",
    "from pathlib import Path\n",
    "import fnmatch\n",
    "from simple_colors import * # pip install simple-colors\n",
    "import warnings #fixed any warning in terminal\n",
    "from pandas.api.types import is_string_dtype\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "import matplotlib.ticker as mtick\n",
    "from matplotlib import ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def georgia_6():\n",
    "    df = pd.read_csv(csv_file)\n",
    "    columns = ['fact', 'Arizona', 'Georgia', 'South Carolina']\n",
    "    df1 = df[columns]\n",
    "    df1 = df1.dropna()\n",
    "    df1[['Arizona', 'Georgia', 'South Carolina']] = df1[['Arizona', 'Georgia', 'South Carolina']].replace('[\\%,]','',regex=True).astype(float)\n",
    "    df1 = pd.DataFrame({'Georgia': df1['Georgia'].tolist(), 'Arizona': df1['Arizona'].tolist(), 'South Carolina': df1['South Carolina'].tolist()}, index=df1['fact'].tolist())\n",
    "    df1.plot.barh()\n",
    "    plt.xlabel('Percentage(%)')\n",
    "    plt.ylabel('Facts')\n",
    "    plt.title('Quick Facts Comparison')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def georgia_5():\n",
    "    df = pd.read_csv(csv_file)\n",
    "    columns = ['Race', '2016', '2020', '% increase']\n",
    "    df1 = df[columns]\n",
    "    df1 = df1.dropna()\n",
    "    df2 = pd.DataFrame({'2020': df1['2020'].tolist(), '2016': df1['2016'].tolist()}, index=df1['Race'].tolist())\n",
    "    df2.plot.barh()\n",
    "    plt.xlabel('Total Votes (million)')\n",
    "    plt.ylabel('Race')\n",
    "    plt.title('Georgia Votes By Race')\n",
    "    df1 = df1.drop(['2016', '2020'], axis=1)\n",
    "    props = dict(boxstyle='round', facecolor='wheat', alpha=0.3)\n",
    "    plt.annotate(f\"{df1.to_string(index=False)}\", xy=(0.6, 0.2), fontsize=11, xycoords='axes fraction', bbox=props)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def georgia_4():\n",
    "    df = pd.read_csv(csv_file)\n",
    "    columns = ['year', 'Metro_DEM_Votes', 'Metro_REP_Votes']\n",
    "    df1 = df[columns]\n",
    "    df1 = df1.dropna()\n",
    "    df1[['year']] = df1[['year']].fillna(0.0).astype(int)\n",
    "    df1 = df1.sort_values('year')\n",
    "    df1 = pd.DataFrame({'Metro_DEM_Votes': df1['Metro_DEM_Votes'].tolist(),'Metro_REP_Votes': df1['Metro_REP_Votes'].tolist()}, index=df1['year'].tolist())\n",
    "    df1.plot.barh()\n",
    "    plt.xlabel('Total Votes (million)')\n",
    "    plt.ylabel('Year')\n",
    "    plt.title('Atlanta Metro Votes')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def georgia_3():\n",
    "    df = pd.read_csv(csv_file)\n",
    "    columns = ['year', 'DEM_Rate', 'REP_Rate']\n",
    "    df1 = df[columns]\n",
    "    df1 = df1.dropna()\n",
    "    df1[['year']] = df1[['year']].fillna(0.0).astype(int)\n",
    "    df1[['DEM_Rate', 'REP_Rate']] = df1[['DEM_Rate', 'REP_Rate']].replace('[\\%,]','',regex=True).astype(float)\n",
    "    df1 = df1.sort_values('year')\n",
    "    df1 = pd.DataFrame({'DEM_Rate': df1['DEM_Rate'].tolist(), 'REP_Rate': df1['REP_Rate'].tolist()}, index=df1['year'].tolist()) \n",
    "    df1.plot.barh()\n",
    "    plt.xlabel('Rate(%)')\n",
    "    plt.ylabel('Year')\n",
    "    plt.title('Democrats vs. Republican Rate in Georgia')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def georgia_2():\n",
    "    from urllib.request import urlopen\n",
    "    import plotly as py\n",
    "    import json\n",
    "    import webbrowser\n",
    "    df = pd.read_csv(csv_file)\n",
    "    #df['fips'] = df['fips'].apply(lambda x: '0'+x if len(x) == 4 else x)\n",
    "    with urlopen('https://raw.githubusercontent.com/plotly/datasets/master/geojson-counties-fips.json') as response:\n",
    "        counties = json.load(response)\n",
    "    #geojson = px.data.election_geojson()\n",
    "    #df = counties_fips_color[(counties_fips_color[\"state_code\"] == \"GA\") | (counties_fips_color[\"state_code\"] == \"FL\")]\n",
    "    states = ['GA', 'SC', 'FL']\n",
    "    df = df[df[\"state_code\"].isin(states)]\n",
    "    #df = counties_fips_color\n",
    "    fig = px.choropleth(df, geojson=counties, locations='fips', color='color',\n",
    "                                scope=\"usa\",\n",
    "                            \n",
    "                            hover_data=[\"state\",\"county\", \"candidate\", \"total_votes\"])\n",
    "    fig.update_geos(\n",
    "                #lonaxis_range=[20, 380],\n",
    "                projection_scale=2.7,\n",
    "                center=dict(lat=31, lon=-83),\n",
    "                visible=True)                      \n",
    "    fig.update_layout(title= {\"text\": \"Georgia vs South Carolina & Florida'\\n' 2020 swing states total_votes\", \"xanchor\": \"center\", \"x\": 0.5, \"y\": 0.95}, \n",
    "        margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0}, showlegend=False)\n",
    "    fig.show()\n",
    "    fig.write_html(\"myplot.html\")\n",
    "    url = 'file://file:///Users/hiep_pham/Desktop/Analysis_Projects/Final_Project/myplot.html'\n",
    "    webbrowser.open(url, new=2)  # open in new tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def swing_state_3():\n",
    "    df = pd.read_csv(csv_file)\n",
    "    states = [\"Arizona\", \"Florida\", \"Georgia\", \"Michigan\", \"Minnesota\", \"Nevada\", \"New Hampshire\", \"North Carolina\", \"Pennsylvania\", \"Texas\"]\n",
    "    df = df.loc[df.state.isin(states)]\n",
    "    width = 0.25\n",
    "    labels = ['AZ', 'FL', 'GA', 'MI', 'MN', 'NV', 'NH', 'NC', 'PA', 'TX']\n",
    "    x = df.state\n",
    "    y1 = df['2020']\n",
    "    y2 = df['2016']\n",
    "    y3 = df['2012']\n",
    "    c1 = df['2020_results']\n",
    "    c2 = df['2016_results']\n",
    "    c3 = df['2012_results']\n",
    "    display = [1, 2, 3]\n",
    "    plt.bar(np.arange(len(x))- width, y1, color = c1, width=width) \n",
    "    plt.bar(np.arange(len(x)), y2, color = c2, width=width)\n",
    "    plt.bar(np.arange(len(x)) + width, y3, color = c3, width=width)\n",
    "    plt.ylabel('Margin Rate (%)')\n",
    "    plt.xlabel('Swing State')\n",
    "    plt.title('Swing States Margin (2020, 2016 & 2012)')\n",
    "    plt.xticks(np.arange(len(x)),labels)\n",
    "    props = dict(boxstyle='round', facecolor='wheat', alpha=0.3)\n",
    "    plt.annotate(\"1st Bar: 2020\", xy=(0.85, 0.97), fontsize=6, xycoords='axes fraction', bbox=props)\n",
    "    plt.annotate(\"2nd Bar: 2016\", xy=(0.85, 0.92), fontsize=6, xycoords='axes fraction', bbox=props)\n",
    "    plt.annotate(\"3rd Bar: 2012\", xy=(0.85, 0.87), fontsize=6, xycoords='axes fraction', bbox=props)\n",
    "    plt.annotate(\"2020\", xy=(-0.45, 0.45), fontsize=7)\n",
    "    plt.annotate(\"2016\", xy=(-0.3, 3.6), fontsize=7)\n",
    "    plt.annotate(\"2012\", xy=(0.1, 9.15), fontsize=7)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def swing_state_2():\n",
    "    df = pd.read_csv(csv_file)\n",
    "    states = [\"Arizona\", \"Florida\", \"Georgia\", \"Michigan\", \"Minnesota\", \"Nevada\", \"New Hampshire\", \"North Carolina\", \"Pennsylvania\", \"Texas\"]\n",
    "    df = df.loc[df.state.isin(states)]\n",
    "    df[['2020_Total_Contributions', '2018_Total_Contributions','2016_Total_Contributions']] = df[['2020_Total_Contributions', '2018_Total_Contributions','2016_Total_Contributions']].replace('[\\$,]','',regex=True).astype(float)\n",
    "    df1 = pd.DataFrame({'2020': df['2020_Total_Contributions'].tolist(), '2018': df['2018_Total_Contributions'].tolist(), '2016': df['2016_Total_Contributions'].tolist()}, index=df['state'].tolist()) \n",
    "    df1.plot.barh()\n",
    "    plt.xlabel('Total Contributions (million)')\n",
    "    plt.ylabel('Swing State')\n",
    "    plt.title('Swing States Contributions')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epi6():\n",
    "    df = pd.read_csv(csv_file)\n",
    "    df1 = df.drop(['state_abbv', 'state_fips', 'website_reg_status', 'website_provisional_status', 'online_reg'],axis=1)\n",
    "    df1 = df1.fillna(0)\n",
    "    # the last column is our label\n",
    "    y_train = df1.iloc[:,-1:]\n",
    "    #drop last column of data\n",
    "    X_train = df1.iloc[:, :-1]\n",
    "    #drop first colum of data\n",
    "    X_test = df1.iloc[:,1:]\n",
    "    # lets have a look on the shape \n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    model = RandomForestRegressor(max_depth=5, random_state=1, n_estimators=1000).fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_train)\n",
    "    prediction = pd.DataFrame({'state':df.state_abbv,'Actual':df1.vep_turnout, 'Prediction': y_pred})\n",
    "    print(prediction)\n",
    "    table_count = prediction.groupby(prediction['state'])['Actual', 'Prediction'].sum() \n",
    "    table_count = table_count.sort_values(by='Prediction', ascending=True)[:10]\n",
    "    word = [table_count]\n",
    "    props = dict(boxstyle='round', facecolor='wheat', alpha=0.3)\n",
    "    ax = table_count.plot.barh()\n",
    "    fmt = '%.2f%%'\n",
    "    xticks = mtick.FormatStrFormatter(fmt)\n",
    "    ax.xaxis.set_major_formatter(xticks)\n",
    "    plt.ylabel('State')\n",
    "    plt.xlabel('VEP Turnout Rate')\n",
    "    ax.set_title(\"Predict Top Ten VEP Turnout By State\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epi5():\n",
    "    df = pd.read_csv(csv_file)\n",
    "    table_count = df.groupby(df['state_abbv'])['vep_turnout'].sum()\n",
    "    table_count = table_count.sort_values(ascending=False)[:10]\n",
    "    payee_index = table_count.index\n",
    "    payee_val = table_count.values\n",
    "    ax = sns.barplot(x = payee_val,y=payee_index,orient='h')\n",
    "    #props = dict(boxstyle='round', facecolor='wheat', alpha=0.3)\n",
    "    #plt.annotate(\"EPI\", xy=(0.5, 0.5), fontsize=15, xycoords='axes fraction', bbox=props)\n",
    "    fmt = '%.2f%%'\n",
    "    xticks = mtick.FormatStrFormatter(fmt)\n",
    "    ax.xaxis.set_major_formatter(xticks)\n",
    "    plt.ylabel('State')\n",
    "    plt.xlabel('VEP Turnout Rate')\n",
    "    ax.set_title(\"Top Ten VEP Turnout By State (2008 - 2018)\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epi4():\n",
    "    df = pd.read_csv(csv_file)\n",
    "    table_count = df.groupby(df['state_abbv'])['uocava_rej'].sum()\n",
    "    table_count = table_count.sort_values(ascending=False)[:10]\n",
    "    payee_index = table_count.index\n",
    "    payee_val = table_count.values\n",
    "    ax = sns.barplot(x = payee_val,y=payee_index,orient='h')\n",
    "    #props = dict(boxstyle='round', facecolor='wheat', alpha=0.3)\n",
    "    #plt.annotate(\"EPI\", xy=(0.5, 0.5), fontsize=15, xycoords='axes fraction', bbox=props)\n",
    "    fmt = '%.2f%%'\n",
    "    xticks = mtick.FormatStrFormatter(fmt)\n",
    "    ax.xaxis.set_major_formatter(xticks)\n",
    "    plt.ylabel('State')\n",
    "    plt.xlabel('UOCAVA ballot Rejection Rate')\n",
    "    ax.set_title(\"Top Ten UOCAVA Ballot Rejection by State (2008 -2018)\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epi3():\n",
    "    df = pd.read_csv(csv_file)\n",
    "    table_count = df.groupby(df['state_abbv'])['prov_rej_all'].sum()\n",
    "    table_count = table_count.sort_values(ascending=False)[:10]\n",
    "    payee_index = table_count.index\n",
    "    payee_val = table_count.values\n",
    "    ax = sns.barplot(x = payee_val,y=payee_index,orient='h')\n",
    "    #props = dict(boxstyle='round', facecolor='wheat', alpha=0.3)\n",
    "    #plt.annotate(\"EPI\", xy=(0.5, 0.5), fontsize=15, xycoords='axes fraction', bbox=props)\n",
    "    fmt = '%.2f%%'\n",
    "    xticks = mtick.FormatStrFormatter(fmt)\n",
    "    ax.xaxis.set_major_formatter(xticks)\n",
    "    plt.ylabel('State')\n",
    "    plt.xlabel('Provisional ballot Rejection Rate')\n",
    "    ax.set_title(\"Top Ten Provisional Ballot Rejection by State (2008 -2018)\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epi2():\n",
    "    df = pd.read_csv(csv_file)\n",
    "    table_count = df.groupby(df['state_abbv'])['abs_rej_all_ballots'].sum()\n",
    "    table_count = table_count.sort_values(ascending=False)[:10]\n",
    "    payee_index = table_count.index\n",
    "    payee_val = table_count.values\n",
    "    ax = sns.barplot(x = payee_val,y=payee_index,orient='h')\n",
    "    #props = dict(boxstyle='round', facecolor='wheat', alpha=0.3)\n",
    "    #plt.annotate(\"EPI\", xy=(0.5, 0.5), fontsize=15, xycoords='axes fraction', bbox=props)\n",
    "    fmt = '%.2f%%'\n",
    "    xticks = mtick.FormatStrFormatter(fmt)\n",
    "    ax.xaxis.set_major_formatter(xticks)\n",
    "    plt.ylabel('State')\n",
    "    plt.xlabel('Absentee ballot Rejection Rate')\n",
    "    ax.set_title(\"Top Ten Absentee Ballot Rejection by State (2008 -2018)\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn2_2layers():\n",
    "    df = pd.read_csv(csv_file)\n",
    "    columns = ['report_year', 'expenditure_amount', 'category_code_full', 'support_oppose_indicator', 'candidate_name', 'cand_office_state', 'cand_office_district', 'election_type']\n",
    "    df = df[columns]\n",
    "    df = df.dropna()\n",
    "\n",
    "    report_year_counts = df.report_year.value_counts()\n",
    "    replace_report_year = report_year_counts[report_year_counts < 10000].index\n",
    "    for app in replace_report_year:\n",
    "        df.report_year =  df.report_year.replace(app,\"Other\")\n",
    "\n",
    "    election_type_count = df.election_type.value_counts()\n",
    "    replace_election_type = election_type_count[election_type_count < 5000].index\n",
    "    for app in replace_election_type:\n",
    "        df.election_type  =  df.election_type.replace(app,\"Other\")\n",
    "\n",
    "    def change_string(value):\n",
    "        if value == \"S\":\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    df[\"support_oppose_indicator\"] = df[\"support_oppose_indicator\"].apply(change_string)\n",
    "\n",
    "    expenditures_cat = df.dtypes[df.dtypes == \"object\"].index.tolist()\n",
    "    le = LabelEncoder()\n",
    "    for col in expenditures_cat:\n",
    "        df = df.apply(lambda col: le.fit_transform(col.astype(str)), axis=0, result_type='expand')\n",
    "    \n",
    "    # Create a OneHotEncoder instance\n",
    "    enc = OneHotEncoder(sparse=False)\n",
    "    encode_df = pd.DataFrame(enc.fit_transform(df[expenditures_cat]))\n",
    "    encode_df.columns = enc.get_feature_names(expenditures_cat)\n",
    "\n",
    "    df = df.merge(encode_df,left_index=True, right_index=True)\n",
    "    df = df.drop(columns = expenditures_cat)\n",
    "\n",
    "    y = df.support_oppose_indicator.values\n",
    "    X = df.drop(\"support_oppose_indicator\", axis=1)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=y)\n",
    "\n",
    "    #Create a StandardScaler instances\n",
    "    scaler = StandardScaler()\n",
    "    X_scaler = scaler.fit(X_train)\n",
    "    # Scale the data\n",
    "    X_train_scaled = X_scaler.transform(X_train)\n",
    "    X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "    number_input_features = len(X_train_scaled[0])\n",
    "    nodes_hidden_layer1 = 80\n",
    "    nodes_hidden_layer2 = 40\n",
    "\n",
    "    #Initial Network\n",
    "    nn = tf.keras.models.Sequential()\n",
    "    nn.add(tf.keras.layers.Dense(units=nodes_hidden_layer1, activation=\"relu\", input_dim=number_input_features))\n",
    "    nn.add(tf.keras.layers.Dense(units=nodes_hidden_layer2, activation=\"relu\"))\n",
    "    nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "    print(nn.summary())\n",
    "    nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "    fit_model = nn.fit(X_train_scaled, y_train, epochs=100)\n",
    "    # Evaluate the model using the test data\n",
    "    model_loss, model_accuracy = nn.evaluate(X_test_scaled, y_test,verbose=2)\n",
    "    print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")\n",
    "    # Export our model to HDF5 file\n",
    "    nn.save(\"independent_expenditures.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r2_2layers():\n",
    "    df = pd.read_csv(csv_file)\n",
    "    columns = ['report_year', 'image_number', 'file_number', 'payee_name', 'expenditure_date', 'dissemination_date', 'expenditure_amount', 'category_code_full', 'support_oppose_indicator', 'candidate_id', 'candidate_name', 'cand_office_state', 'cand_office_district', \n",
    "    'election_type', 'sub_id']\n",
    "    df = df[columns]\n",
    "    df = df.dropna()\n",
    "    df =  df.fillna(0)\n",
    "    #Create category_columns and numeric_columns variables\n",
    "    numeric_columns = []\n",
    "    category_columns = []\n",
    "    for col in df.columns:\n",
    "        if is_string_dtype(df[col]) == True:\n",
    "            category_columns.append(col)\n",
    "        elif is_numeric_dtype(df[col]) == True:\n",
    "            numeric_columns.append(col)\n",
    "    #Create dummy variables for the category_columns and merge on the numeric_columns to create an X dataset\n",
    "    category_columns = pd.get_dummies(df[category_columns])\n",
    "    X = df[numeric_columns].merge(category_columns, left_index= True, right_index= True)\n",
    "    #Create an y dataset\n",
    "    y = df['expenditure_amount'].values\n",
    "    # Split X and y into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "    # Scale X_train and X_test\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.fit_transform(X_test)\n",
    "\n",
    "    # Create a neural network model with keras\n",
    "    nn = tf.keras.models.Sequential()\n",
    "    # Add a hidden layer with twice as many neurons as there are inputs. Use 'relu'\n",
    "    n_input = len(X_train_scaled[0])\n",
    "\n",
    "    n_hidden = n_input * 2\n",
    "    n_hidden_layer2 = n_input * 2 #2nd hidden layer\n",
    "\n",
    "    nn.add(tf.keras.layers.Dense(units=n_hidden, input_dim=n_input, activation='relu'))\n",
    "    nn.add(tf.keras.layers.Dense(units=n_hidden_layer2, activation='relu')) #2nd hidden layer\n",
    "\n",
    "    # add an output layer with a 'linear' activation function.\n",
    "    nn.add(tf.keras.layers.Dense(units=1,  activation='linear'))\n",
    "    # print a summary of the model\n",
    "    print(nn.summary())\n",
    "    # compile the model using the \"adam\" optimizer and \"mean_squared_error\" loss function\n",
    "    nn.compile(loss='mean_squared_error' , optimizer='adam' , metrics=['mse'])\n",
    "    # train the model for 100 epochs\n",
    "    model = nn.fit(X_train_scaled, y_train, epochs=100)\n",
    "    # predict values for the train and test sets\n",
    "    y_train_pred = nn.predict(X_train_scaled)\n",
    "    y_test_pred = nn.predict(X_test_scaled)\n",
    "    # score the training predictions with r2_score()\n",
    "    print(f\"r2_score of y_train: {r2_score(y_train, y_train_pred)}\")\n",
    "    # score the test predictions with r2_score()\n",
    "    print(f\"r2_score of y_test: {r2_score(y_test, y_test_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expenditures_6():\n",
    "    df = pd.read_csv(csv_file)\n",
    "    #Trump\n",
    "    df1 = df[df['candidate_name'].notna()]\n",
    "    support =['S','SUP']\n",
    "    word1 = [\"TRUMP\", \"Trump\"]\n",
    "    for i in range(len(word1)):\n",
    "        trump_entry = df1[df1.candidate_name.str.contains(word1[i])]\n",
    "    trump_entry = trump_entry[trump_entry.support_oppose_indicator.isin(support)]\n",
    "    #Biden\n",
    "    df2 = df[df['candidate_name'].notna()]\n",
    "    support =['S','SUP']\n",
    "    word2 = [\"BIDEN\", \"Biden\"]\n",
    "    for i in range(len(word2)):\n",
    "        biden_entry = df2[df2.candidate_name.str.contains(word2[i])]\n",
    "    biden_entry = biden_entry[biden_entry.support_oppose_indicator.isin(support)]\n",
    "\n",
    "    total_trump = len(trump_entry)\n",
    "    total_biden = len(biden_entry)\n",
    "    total = len(df.cand_office_state)\n",
    "    rate_trump = total_trump/total * 100\n",
    "    rate_biden = total_biden/total * 100\n",
    "    support_rate_list = [rate_biden, rate_trump]\n",
    "    candidate = ['BIDEN, JOSEPH R JR', 'TRUMP, DONALD J']\n",
    "    support_prob = pd.DataFrame({'Candidate':candidate,'Support Rate':support_rate_list})\n",
    "    sns.barplot(data=support_prob,x='Candidate',y='Support Rate')\n",
    "    props = dict(boxstyle='round', facecolor='wheat', alpha=0.3)\n",
    "    plt.annotate(f\"Total Biden Support: {total_biden}\", xy=(0.5, 0.7), fontsize=12, xycoords='axes fraction', bbox=props)\n",
    "    plt.annotate(f\"Total Trump Support: {total_trump}\", xy=(0.5, 0.6), fontsize=12, xycoords='axes fraction', bbox=props)\n",
    "    plt.ylabel('Support Rate')\n",
    "    plt.xlabel('Candidate')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expenditures_5():\n",
    "    df = pd.read_csv(csv_file)\n",
    "    df = df[df['candidate_name'].notna()]\n",
    "    support =['S','SUP']\n",
    "    words = [\"BIDEN\", \"Biden\"]\n",
    "    #biden_entry = df[df.candidate_name == 'Biden, Joseph']\n",
    "    for i in range(len(words)):\n",
    "        biden_entry = df[df.candidate_name.str.contains(words[i])]\n",
    "    biden_entry = biden_entry[biden_entry.support_oppose_indicator.isin(support)]\n",
    "    #biden_state = biden_entry[(biden_entry[['cand_office_state']] != 0).all(axis=1)]\n",
    "    #biden_state = biden_entry.loc[biden_entry['cand_office_state']!=0].dropna()\n",
    "    biden_state = biden_entry.dropna(subset=['cand_office_state'])\n",
    "    biden_state = biden_state[(biden_state[['cand_office_state']] != '0').all(axis=1)]\n",
    "    biden_state = biden_state.groupby(biden_state.cand_office_state)\\\n",
    "                [['cand_office_state','support_oppose_indicator']].size()\n",
    "    biden_index = biden_state.index\n",
    "    biden_val = biden_state.values\n",
    "    fig,ax = plt.subplots(figsize=(8,6))\n",
    "    sns.barplot(x = biden_val,y=biden_index,orient='h',ax=ax)\n",
    "    props = dict(boxstyle='round', facecolor='wheat', alpha=0.3)\n",
    "    plt.annotate(\"Number of contributor Supporting Biden by state\", xy=(0.3, 0.5), fontsize=12, xycoords='axes fraction', bbox=props)\n",
    "    plt.ylabel('State')\n",
    "    plt.xlabel('Count')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expenditures_4():\n",
    "    df = pd.read_csv(csv_file)\n",
    "    df = df[df['candidate_name'].notna()]\n",
    "    support =['S','SUP']\n",
    "    words = [\"TRUMP\", \"Trump\"]\n",
    "    for i in range(len(words)):\n",
    "        trump_entry = df[df.candidate_name.str.contains(words[i])]\n",
    "    trump_entry = trump_entry[trump_entry.support_oppose_indicator.isin(support)]\n",
    "    trump_state = trump_entry.groupby(trump_entry.cand_office_state)\\\n",
    "                [['cand_office_state','support_oppose_indicator']].size()\n",
    "    trump_index = trump_state.index\n",
    "    trump_val = trump_state.values\n",
    "    fig,ax = plt.subplots(figsize=(8,6))\n",
    "    sns.barplot(x = trump_val,y=trump_index,orient='h',ax=ax)\n",
    "    props = dict(boxstyle='round', facecolor='wheat', alpha=0.3)\n",
    "    plt.annotate(\"Number of contributor Supporting Trump by state\", xy=(0.2, 0.5), fontsize=12, xycoords='axes fraction', bbox=props)\n",
    "    plt.ylabel('State')\n",
    "    plt.xlabel('Count')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expenditures_3():\n",
    "    df = pd.read_csv(csv_file)\n",
    "    table_count = df.groupby(df.category_code_full)['expenditure_amount'].sum()\n",
    "    table_count = table_count.sort_values(ascending=False)[:10]\n",
    "    category_code_idx = table_count.index\n",
    "    category_code_val = table_count.values\n",
    "    fig,ax = plt.subplots(figsize=(8,6))\n",
    "    sns.barplot(x = category_code_val,y=category_code_idx,orient='h')\n",
    "    props = dict(boxstyle='round', facecolor='wheat', alpha=0.3)\n",
    "    plt.annotate(\"Top Ten Category vs Expenditure Amount\", xy=(0.3, 0.5), fontsize=15, xycoords='axes fraction', bbox=props)\n",
    "    plt.ylabel('Category')\n",
    "    plt.xlabel('Expenditure Amount')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expenditures_2():\n",
    "    df = pd.read_csv(csv_file)\n",
    "    table_count = df.groupby(df['payee_name'])['expenditure_amount'].sum()\n",
    "    table_count = table_count.sort_values(ascending=False)[:10]\n",
    "    payee_index = table_count.index\n",
    "    payee_val = table_count.values\n",
    "    sns.barplot(x = payee_val,y=payee_index,orient='h')\n",
    "    props = dict(boxstyle='round', facecolor='wheat', alpha=0.3)\n",
    "    plt.annotate(\"Top Ten Payee\", xy=(0.5, 0.5), fontsize=15, xycoords='axes fraction', bbox=props)\n",
    "    plt.ylabel('Payee Name')\n",
    "    plt.xlabel('Expenditure Amount')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def senate_predict():\n",
    "    while True:\n",
    "        df = pd.read_csv(csv_file)\n",
    "        df = df.dropna()\n",
    "        df= df[df['Results'] != 0]\n",
    "        df.rename(columns = {'party_simplified' : 'winning_party'},inplace = True)\n",
    "        try:\n",
    "            state = input(\"Please enter the STATE to predict: \").strip().upper()   \n",
    "            df = df.loc[df.state_po == state]   \n",
    "            #print(red(\"Typo! Please try again.\"))\n",
    "            columns = ['state_po', '_year', 'candidatevotes', 'totalvotes','winning_party']\n",
    "            df = df[columns]    \n",
    "            #print(f\"Here's {state} DataFrame {df}\"'\\n')\n",
    "            print(df)\n",
    "\n",
    "            #FIRST PREDICTION\n",
    "            ##the last column is our label\n",
    "            y_train = df.totalvotes.values\n",
    "            #drop last column of data\n",
    "            X_train = df.drop(['winning_party', 'state_po'], axis=1)\n",
    "            #drop first colum of data\n",
    "            X_test = df.drop(['winning_party', 'state_po', '_year'], axis=1)\n",
    "            from sklearn.ensemble import RandomForestRegressor\n",
    "            model = RandomForestRegressor(max_depth=5, random_state=1, n_estimators=1000).fit(X_train, y_train)\n",
    "            y_pred = model.predict(X_train)\n",
    "            new_pred = y_pred[-1]\n",
    "            prediction = pd.DataFrame({'State':df.state_po,'Last_Election':df.totalvotes, 'Next_Election_Pred': y_pred.astype(int)}, index=None)\n",
    "            prediction = prediction.iloc[[-1]]\n",
    "            print (prediction.to_string(index=False))\n",
    "\n",
    "            y = df.totalvotes.values\n",
    "            #drop last column of data\n",
    "            X = df.drop(['winning_party', 'state_po'], axis=1)\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X,y, random_state=1, test_size=0.01) #0.2 means only 20% sample\n",
    "            X_train.shape, X_test.shape, y_train.shape, y_test.shape\n",
    "            model = RandomForestRegressor(max_depth=5, random_state=1, n_estimators=1000).fit(X_train, y_train)\n",
    "            y_pred = model.predict(X_train).astype(int)\n",
    "            #print(blue(f\"Predict_Score of {state}: {model.score(X_train, y_train)}\"))\n",
    "            total_votes_pred = y_pred[-1]\n",
    "            total_votes_pred\n",
    "\n",
    "             #SECOND PREDICTION\n",
    "            df.winning_party = df. winning_party.replace({'DEMOCRAT': 1, 'REPUBLICAN': 2, 'LIBERTARIAN': 3, 'OTHER': 4})\n",
    "            # the last column is our label\n",
    "            y = df.winning_party.values\n",
    "            #drop last column of data\n",
    "            X = df.drop(['winning_party', 'state_po'], axis=1)\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X,y, random_state=1, test_size=0.01) #0.2 means only 20% sample\n",
    "            #print(X_train.shape)\n",
    "            model2 = RandomForestRegressor(max_depth=5, random_state=1, n_estimators=1000).fit(X_train, y_train)\n",
    "            y_pred = model2.predict(X_train)\n",
    "            #print(len(y_pred))\n",
    "            print(blue(f\"Predict_Score of {state}: {model2.score(X_train, y_train)}\"))\n",
    "            #print(y_pred)\n",
    "        except ValueError:\n",
    "            print(red(\"Typo! Please try again.\"'\\n'))\n",
    "            break\n",
    "\n",
    "        lst1 = [x for x in y_train[-20:] if x == 1] \n",
    "        dem = len(lst1)\n",
    "        lst2 = [x for x in y_train[-20:] if x == 2] \n",
    "        rep = len(lst2)\n",
    "        lst3 = [x for x in y_train[-20:] if (x ==3)] \n",
    "        lib = len(lst3)\n",
    "        lst4 = [x for x in y_train[-20:] if (x != 1 and x !=2 and x !=3)] \n",
    "        other = len(lst4)\n",
    "        if other > dem and other > rep:\n",
    "            print_pred = f\"Predict OTHER will win in {state}\"\n",
    "            print(green(f\"Predict OTHER will win in {state} next Election.\"))\n",
    "        elif dem > rep and dem >= other:      \n",
    "            print_pred = f\"Predict SENATE DEMOCRAT will win in {state}\"\n",
    "            print(blue(f\"Predict SENATE DEMOCRAT will win in {state} next Election.\"))\n",
    "        elif rep >= dem and rep >= other:\n",
    "            print_pred = f\"Predict SENATE REPUBLICAN will win in {state}\"\n",
    "            print(red(f\"Predict SENATE REPUBLICAN will win in {state} next Election.\"))\n",
    "        #print(dem, rep, lib, other)\n",
    "\n",
    "        #First Plot\n",
    "        word = [\"\"]\n",
    "        old_votes = df['totalvotes'].iloc[-1]\n",
    "        df1 = pd.DataFrame({\"Next_Election_Pred_Votes\": new_pred, \"Last_Elecction_Votes\": old_votes}, index=word) \n",
    "        props = dict(boxstyle='round', facecolor='wheat', alpha=0.3)\n",
    "        df1.plot.barh()\n",
    "        plt.annotate(f\"{prediction.to_string(index=False)}\", xy=(0.25, 0.05), fontsize=11, xycoords='axes fraction', bbox=props)\n",
    "        plt.annotate(print_pred, xy=(0.25, 0.18), fontsize=11, xycoords='axes fraction', bbox=props)\n",
    "        plt.xlabel('Total Votes')\n",
    "        plt.title(f\"Next Senate Elections Predictions in {state}\")\n",
    "        plt.show()\n",
    "\n",
    "        #Second Plot\n",
    "        try:\n",
    "            a = [int(x) for x in input(\"Enter a list[year, candidatevotes, totalvotes] to test the prediction: \").split()]\n",
    "        except:\n",
    "            print(red(\"Typo! Please try again.\"'\\n'))\n",
    "            break\n",
    "        if a == []:\n",
    "            print(red(\"Typo! Please try again.\"'\\n'))\n",
    "            break\n",
    "        old_year = df['_year'].iloc[-1]\n",
    "        new_year = a[0]\n",
    "        new_votes = a[2]\n",
    "        test_prediction = model2.predict([a])\n",
    "        word = [\"\"]\n",
    "        old_votes = df['totalvotes'].iloc[-1]\n",
    "        df = pd.DataFrame({f\"{new_year}_PredictTotalVotes\": new_votes, f\"{old_year}_TotalVotes\": old_votes}, index=word) \n",
    "        props = dict(boxstyle='round', facecolor='wheat', alpha=0.3)\n",
    "        df.plot.barh()\n",
    "        if test_prediction < [1.5]:\n",
    "            plt.annotate(f\"Predict SENATE DEMOCRAT will win in {state}\", xy=(0.25, 0.1), fontsize=11, xycoords='axes fraction', bbox=props)\n",
    "        elif test_prediction > [1.5]:\n",
    "            plt.annotate(f\"Predict SENATE PUBLICAN will win in {state}\", xy=(0.2, 0.1), fontsize=11, xycoords='axes fraction', bbox=props)\n",
    "        else:\n",
    "            plt.annotate(f\"Predict Other will win in {state}\", xy=(0.2, 0.1), fontsize=11, xycoords='axes fraction', bbox=props)\n",
    "        plt.xlabel('Total Votes')\n",
    "        plt.title(f\"{new_year} Senate Elections Predictions in {state}\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_2layers():\n",
    "    df = pd.read_csv(csv_file)\n",
    "    #Create category_columns and numeric_columns variables\n",
    "    numeric_columns = []\n",
    "    category_columns = []\n",
    "    for col in df.columns:\n",
    "        if is_string_dtype(df[col]) == True:\n",
    "            category_columns.append(col)\n",
    "        elif is_numeric_dtype(df[col]) == True:\n",
    "            numeric_columns.append(col)\n",
    "    #Create dummy variables for the category_columns and merge on the numeric_columns to create an X dataset\n",
    "    category_columns = pd.get_dummies(df[category_columns])\n",
    "    X = df[numeric_columns].merge(category_columns, left_index= True, right_index= True)\n",
    "    X = X.fillna(0)\n",
    "    #Create an y dataset\n",
    "    y = df['totalvotes'].values\n",
    "    # Split X and y into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "    # Scale X_train and X_test\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.fit_transform(X_test)\n",
    "\n",
    "    # Create a neural network model with keras\n",
    "    nn = tf.keras.models.Sequential()\n",
    "    # Add a hidden layer with twice as many neurons as there are inputs. Use 'relu'\n",
    "    n_input = len(X_train_scaled[0])\n",
    "\n",
    "    n_hidden = n_input * 2\n",
    "    n_hidden_layer2 = n_input * 2 #2nd hidden layer\n",
    "\n",
    "    nn.add(tf.keras.layers.Dense(units=n_hidden, input_dim=n_input, activation='relu'))\n",
    "    nn.add(tf.keras.layers.Dense(units=n_hidden_layer2, activation='relu')) #2nd hidden layer\n",
    "\n",
    "    # add an output layer with a 'linear' activation function.\n",
    "    nn.add(tf.keras.layers.Dense(units=1,  activation='linear'))\n",
    "    # print a summary of the model\n",
    "    print(nn.summary())\n",
    "    # compile the model using the \"adam\" optimizer and \"mean_squared_error\" loss function\n",
    "    nn.compile(loss='mean_squared_error' , optimizer='adam' , metrics=['mse'])\n",
    "    # train the model for 100 epochs\n",
    "    model = nn.fit(X_train_scaled, y_train, epochs=100)\n",
    "    # predict values for the train and test sets\n",
    "    y_train_pred = nn.predict(X_train_scaled)\n",
    "    y_test_pred = nn.predict(X_test_scaled)\n",
    "    # score the training predictions with r2_score()\n",
    "    print(f\"r2_score of y_train: {r2_score(y_train, y_train_pred)}\")\n",
    "    # score the test predictions with r2_score()\n",
    "    print(f\"r2_score of y_test: {r2_score(y_test, y_test_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_1layer():\n",
    "    df = pd.read_csv(csv_file)\n",
    "    #Create category_columns and numeric_columns variables\n",
    "    numeric_columns = []\n",
    "    category_columns = []\n",
    "    for col in df.columns:\n",
    "        if is_string_dtype(df[col]) == True:\n",
    "            category_columns.append(col)\n",
    "        elif is_numeric_dtype(df[col]) == True:\n",
    "            numeric_columns.append(col)\n",
    "    #Create dummy variables for the category_columns and merge on the numeric_columns to create an X dataset\n",
    "    category_columns = pd.get_dummies(df[category_columns])\n",
    "    X = df[numeric_columns].merge(category_columns, left_index= True, right_index= True)\n",
    "    #Create an y dataset\n",
    "    y = df['totalvotes'].values\n",
    "    # Split X and y into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "    # Scale X_train and X_test\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.fit_transform(X_test)\n",
    "\n",
    "    # Create a neural network model with keras\n",
    "    nn = tf.keras.models.Sequential()\n",
    "    # Add a hidden layer with twice as many neurons as there are inputs. Use 'relu'\n",
    "    n_input = len(X_train_scaled[0])\n",
    "\n",
    "    n_hidden = n_input * 2\n",
    "    #n_hidden_layer2 = n_input * 2 #2nd hidden layer\n",
    "\n",
    "    nn.add(tf.keras.layers.Dense(units=n_hidden, input_dim=n_input, activation='relu'))\n",
    "    #nn.add(tf.keras.layers.Dense(units=n_hidden_layer2, activation='relu')) #2nd hidden layer\n",
    "\n",
    "    # add an output layer with a 'linear' activation function.\n",
    "    nn.add(tf.keras.layers.Dense(units=1,  activation='linear'))\n",
    "    # print a summary of the model\n",
    "    print(nn.summary())\n",
    "    # compile the model using the \"adam\" optimizer and \"mean_squared_error\" loss function\n",
    "    nn.compile(loss='mean_squared_error' , optimizer='adam' , metrics=['mse'])\n",
    "    # train the model for 100 epochs\n",
    "    model = nn.fit(X_train_scaled, y_train, epochs=100)\n",
    "    # predict values for the train and test sets\n",
    "    y_train_pred = nn.predict(X_train_scaled)\n",
    "    y_test_pred = nn.predict(X_test_scaled)\n",
    "    # score the training predictions with r2_score()\n",
    "    print(f\"r2_score of y_train: {r2_score(y_train, y_train_pred)}\")\n",
    "    # score the test predictions with r2_score()\n",
    "    print(f\"r2_score of y_test: {r2_score(y_test, y_test_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_2():\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    df = pd.read_csv(csv_file)\n",
    "    df = df[df.loc[:] != 'LIB'].dropna()\n",
    "    df = df.drop(df.columns[0], axis=1)\n",
    "    df.party = df.party.replace({'DEM': 1, 'REP': 2})\n",
    "    dataset = df.drop(['state', 'party'],axis=1)\n",
    "    # the last column is our label\n",
    "    y_train = dataset.iloc[:,-1:]\n",
    "    #drop last column of data\n",
    "    X_train = dataset.iloc[:, :-1]\n",
    "    #drop first colum of data\n",
    "    X_test = dataset.iloc[:,1:]\n",
    "    model = RandomForestRegressor(max_depth=5, random_state=1, n_estimators=1000).fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_train)\n",
    "    print(y_pred)\n",
    "    print(f\"Predict_Score: {model.score(X_train, y_train)}\")\n",
    "    prediction = pd.DataFrame({'state':df.state,'party':df.party, 'prediction_2024': y_pred.astype(int)})\n",
    "    my_colors = list(islice(cycle(['b', 'r']), None, len(prediction)))\n",
    "    prediction.party = prediction.party.map({1: 'DEM', 2: 'REP'})\n",
    "    prediction.groupby('party')['prediction_2024'].sum().plot.bar(ylabel= \"candidatevotes\", title=\"2024 Party Prediction\", color=my_colors)\n",
    "    predict_winner = prediction.groupby('party')['prediction_2024'].sum()\n",
    "    print(predict_winner)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minority_2(): \n",
    "    import plotly.figure_factory as ff\n",
    "    import numpy as np \n",
    "    import pandas as pd\n",
    "    import plotly as py\n",
    "\n",
    "    NE_states = ['Georgia', 'South Carolina']\n",
    "    df = pd.read_csv(csv_file)\n",
    "    df = df[df['STNAME'].isin(NE_states)]\n",
    "\n",
    "    values = df['TOT_POP'].tolist()\n",
    "    fips = df['FIPS'].tolist()\n",
    "    count=df['Black'].tolist()\n",
    "\n",
    "    color = [\"#8dd3c7\", \"#ffffb3\", \"#bebada\", \"#fb8072\",\n",
    "                \"#80b1d3\", \"#fdb462\", \"#b3de69\", \"#fccde5\",\n",
    "                \"#d9d9d9\", \"#bc80bd\", \"#ccebc5\", \"#ffed6f\",\n",
    "                \"#8dd3c7\", \"#ffffb3\", \"#bebada\", \"#fb8072\",\n",
    "                \"#80b1d3\", \"#fdb462\", \"#b3de69\", \"#fccde5\",\n",
    "                \"#d9d9d9\", \"#bc80bd\", \"#ccebc5\", \"#ffed6f\",\n",
    "                \"#8dd3c7\", \"#ffffb3\", \"#bebada\", \"#fb8072\",\n",
    "                \"#80b1d3\", \"#fdb462\", \"#b3de69\", \"#fccde5\",\n",
    "                \"#d9d9d9\", \"#bc80bd\", \"#ccebc5\", \"#ffed6f\"]\n",
    "    colorscale = color * 6\n",
    "\n",
    "    fig = ff.create_choropleth(\n",
    "        fips=fips, values=values,\n",
    "        #colorscale=colorscale, round_legend_values=True,\n",
    "        simplify_county=0, simplify_state=0,\n",
    "        scope=NE_states, county_outline={'color': 'rgb(255,255,255)', 'width': 0.5},\n",
    "        state_outline={'color': 'rgb(0,0,0)', 'width': 2},\n",
    "        #show_hover=True, centroid_marker={'opacity': 1},\n",
    "        legend_title='Population per county',\n",
    "        title='Georgia vs South Carolina Population'\n",
    "\n",
    "    )\n",
    "\n",
    "    fig.layout.template = None\n",
    "    fig.show()\n",
    "    py.offline.plot(fig,\n",
    "    filename='Georgia vs South Carolina.html',\n",
    "    include_plotlyjs='https://cdn.plot.ly/plotly-1.42.3.min.js')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def county_4():\n",
    "    from urllib.request import urlopen\n",
    "    import plotly as py\n",
    "    import json\n",
    "    import webbrowser\n",
    "    df = pd.read_csv(csv_file)\n",
    "    #df['fips'] = df['fips'].apply(lambda x: '0'+x if len(x) == 4 else x)\n",
    "    with urlopen('https://raw.githubusercontent.com/plotly/datasets/master/geojson-counties-fips.json') as response:\n",
    "        counties = json.load(response)\n",
    "    #geojson = px.data.election_geojson()\n",
    "    #df = counties_fips_color[(counties_fips_color[\"state_code\"] == \"GA\") | (counties_fips_color[\"state_code\"] == \"FL\")]\n",
    "    states = ['GA', 'SC', 'FL']\n",
    "    df = df[df[\"state_code\"].isin(states)]\n",
    "    #df = counties_fips_color\n",
    "    fig = px.choropleth(df, geojson=counties, locations='fips', color='color',\n",
    "                                scope=\"usa\",\n",
    "                            \n",
    "                            hover_data=[\"state\",\"county\", \"candidate\", \"total_votes\"])\n",
    "    fig.update_geos(\n",
    "                #lonaxis_range=[20, 380],\n",
    "                projection_scale=2.7,\n",
    "                center=dict(lat=31, lon=-83),\n",
    "                visible=True)                      \n",
    "    fig.update_layout(title= {\"text\": \"Georgia vs South Carolina & Florida'\\n' 2020 swing states total_votes\", \"xanchor\": \"center\", \"x\": 0.5, \"y\": 0.95}, \n",
    "        margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0}, showlegend=False)\n",
    "    fig.show()\n",
    "    fig.write_html(\"myplot.html\")\n",
    "    url = 'file://file:///Users/hiep_pham/Desktop/Analysis_Projects/Final_Project/myplot.html'\n",
    "    webbrowser.open(url, new=2)  # open in new tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def county_3():\n",
    "    df = pd.read_csv(csv_file)\n",
    "    plt.scatter(df.median_age,df.total_votes)\n",
    "    plt.xlabel(\"median_age\")\n",
    "    plt.ylabel('Total_Votes')\n",
    "    plt.title(\"median_age vs Total_Votes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def county_2():\n",
    "    df = pd.read_csv(csv_file)\n",
    "    y = df.total_votes\n",
    "    X = df.population.values.reshape(-1, 1)\n",
    "    model = LinearRegression().fit(X, y)\n",
    "    y_pred = model.predict(X)\n",
    "    plt.scatter(X,y)\n",
    "    plt.plot(X, y_pred, color='red')\n",
    "    plt.xlabel(\"Population\")\n",
    "    plt.ylabel('Total_Votes')\n",
    "    plt.title(\"Population vs Total_Votes'\\n' Linear Regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_3():\n",
    "    df = pd.read_csv(csv_file)\n",
    "    df = df[['year','House winner spending', 'Senate winner spending']] \n",
    "    df = df.sort_values(by='year', ascending=True)\n",
    "    df.plot(\n",
    "    x = 'year', \n",
    "    kind = 'barh', \n",
    "    stacked = True, \n",
    "    title = 'House winner vs. Senate winner Spending',)\n",
    "    plt.xlabel('Spending')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_2():\n",
    "    df = pd.read_csv(csv_file)\n",
    "    df = df[['year','Democrats', 'Republicans']] \n",
    "    df = df.sort_values(by='year', ascending=True)\n",
    "    df.plot(\n",
    "    x = 'year', \n",
    "    kind = 'barh', \n",
    "    stacked = True, \n",
    "    title = 'Democrats vs. Republican Spending',)\n",
    "    plt.xlabel('Spending')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df():\n",
    "    df = pd.read_csv(csv_file)\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "       plt.close()\n",
    "       csv_file = input(\"Import CSV_file to analyze: \").strip()\n",
    "       file_name1 = os.path.split(os.path.abspath(csv_file))[-1] \n",
    "       if len(csv_file) < 2: #hit enter to quit csv files while loop(enter is len = 1) \n",
    "              break  \n",
    "       elif not file_name1.endswith('csv'):\n",
    "              continue  # ignore it if not csv files\n",
    "       file_name, file_extension = os.path.splitext(file_name1)   \n",
    "\n",
    "       list1 = [\"Option 1: Print Data Frame\",\n",
    "              \"Option 2: Democrats vs. Republican Spending\",\n",
    "              \"Option 3: House winner vs. Senate winner Spending\"\n",
    "              ]\n",
    "       list2 = [\"Option 1: Print Data Frame\",\n",
    "              \"Option 2: Population vs Total_Votes & Linear Regression\",\n",
    "              \"Option 3: Median Age vs Total_Votes\",\n",
    "              \"Option 4: 2020 swing states total_votes(Georgia vs South Carolina & Florida)\",\n",
    "              ]\n",
    "       list3 = [\"Option 1: Print Data Frame\",\n",
    "              \"Option 2: Georgia vs South Carolina Population\",\n",
    "              ]\n",
    "       list4 = [\"Option 1: Print Data Frame\",\n",
    "              \"Option 2: 2024 Party Prediction (Randomforestclassifier)\",\n",
    "              ]\n",
    "       list5 = [\"Option 1: Print Data Frame\",\n",
    "              \"Option 2: neural network with 1 hidden layer\",\n",
    "              \"Option 3: neural network with 2 hidden layers\",\n",
    "              \"Option 4: Senate Elections Predictions By State\",\n",
    "              ]\n",
    "       list6 = [\"Option 1: Print Data Frame\",\n",
    "              \"Option 2: Top Ten Payeer\",\n",
    "              \"Option 3: Top Ten Category vs Expenditure Amount\",\n",
    "              \"Option 4: Number of contributor Supporting Trump by state\",\n",
    "              \"Option 5: Number of contributor Supporting Biden by state\",\n",
    "              \"Option 6: Trump vs Biden Supporting Rate\",\n",
    "              \"Option 7: neural network with 2 hidden layers\",\n",
    "              ]\n",
    "       list7 = [\"Option 1: Print Data Frame\",\n",
    "              \"Option 2: Top Ten Absentee Ballot Rejection by State\",\n",
    "              \"Option 3: Top Ten Provisional Ballot Rejection by State\",\n",
    "              \"Option 4: Top Ten UOCAVA Ballot Rejection by State\",\n",
    "              \"Option 5: Top Ten VEP Turnout By State \",\n",
    "              \"Option 6: Predict Top Ten VEP Turnout By State\",\n",
    "              ]\n",
    "       list8 = [\"Option 1: Print Data Frame\",\n",
    "              \"Option 2: Swing States Contributions\",\n",
    "              \"Option 3: Swing States Margin\",      \n",
    "              ]\n",
    "       list9 = [\"Option 1: Print Data Frame\",\n",
    "              \"Option 2: Georgia Votes By County\",\n",
    "              \"Option 3: Democrats vs. Republican Rate in Georgia\",\n",
    "              \"Option 4: Atlanta Metro Votese\",\n",
    "              \"Option 5: Georgia Votes By Race\",\n",
    "              \"Option 6: Quick Facts Comparison\",\n",
    "              ]\n",
    "       while True and len(file_name) > 2:\n",
    "              if file_name.find('CostOf') != -1:\n",
    "                     print(blue(f\"The following options are available for {file_name1}:\"))\n",
    "                     print(*list1,sep='\\n')\n",
    "                     func = input(\"Please input the option #: \")\n",
    "                     print(\"\")\n",
    "              elif file_name.find('president_counties') != -1:\n",
    "                     print(blue(f\"The following options are available for {file_name1}:\"))\n",
    "                     print(*list2,sep='\\n')\n",
    "                     func = input(\"Please input the option #: \")\n",
    "                     print(\"\")\n",
    "              elif file_name.find('minority') != -1:\n",
    "                     print(blue(f\"The following options are available for {file_name1}:\"))\n",
    "                     print(*list3,sep='\\n')\n",
    "                     func = input(\"Please input the option #: \")\n",
    "                     print(\"\")\n",
    "              elif file_name.find('president_dataset') != -1:\n",
    "                     print(blue(f\"The following options are available for {file_name1}:\"))\n",
    "                     print(*list4,sep='\\n')\n",
    "                     func = input(\"Please input the option #: \")\n",
    "                     print(\"\")\n",
    "              elif file_name.find('senate_dataset') != -1:\n",
    "                     print(blue(f\"The following options are available for {file_name1}:\"))\n",
    "                     print(*list5,sep='\\n')\n",
    "                     func = input(\"Please input the option #: \")\n",
    "                     print(\"\")\n",
    "              elif file_name.find('independent_expenditures') != -1:\n",
    "                     print(blue(f\"The following options are available for {file_name1}:\"))\n",
    "                     print(*list6,sep='\\n')\n",
    "                     func = input(\"Please input the option #: \")\n",
    "                     print(\"\")\n",
    "              elif file_name.find('epi') != -1:\n",
    "                     print(blue(f\"The following options are available for {file_name1}:\"))\n",
    "                     print(*list7,sep='\\n')\n",
    "                     func = input(\"Please input the option #: \")\n",
    "                     print(\"\")\n",
    "              elif file_name.find('swing_state') != -1:\n",
    "                     print(blue(f\"The following options are available for {file_name1}:\"))\n",
    "                     print(*list8,sep='\\n')\n",
    "                     func = input(\"Please input the option #: \")\n",
    "                     print(\"\")\n",
    "              elif file_name.find('Georgia') != -1:\n",
    "                     print(blue(f\"The following options are available for {file_name1}:\"))\n",
    "                     print(*list9,sep='\\n')\n",
    "                     func = input(\"Please input the option #: \")\n",
    "                     print(\"\")\n",
    "              \n",
    "              if func == \"\": #hit enter to quit function while loop\n",
    "                     break\n",
    "              elif func not in (\"1\", \"2\", \"3\", \"4\", \"5\", '6','7'):\n",
    "                     print(red(\"Typo! Please try again.\"))\n",
    "              if func == \"1\" and file_name.find('CostOf') != -1:\n",
    "                     df()\n",
    "              elif func == \"2\" and file_name.find('CostOf') != -1:\n",
    "                     cost_2()\n",
    "              elif func == \"3\" and file_name.find('CostOf') != -1:\n",
    "                     cost_3()\n",
    "              elif func == \"1\" and file_name.find('president_counties') != -1:\n",
    "                     df()       \n",
    "              elif func == \"2\" and file_name.find('president_counties') != -1:\n",
    "                     county_2()\n",
    "              elif func == \"3\" and file_name.find('president_counties') != -1:\n",
    "                     county_3()\n",
    "              elif func == \"4\" and file_name.find('president_counties') != -1:\n",
    "                     county_4()\n",
    "              elif func == \"1\" and file_name.find('minority') != -1:\n",
    "                     df()\n",
    "              elif func == \"2\" and file_name.find('minority') != -1:\n",
    "                     minority_2()\n",
    "              elif func == \"1\" and file_name.find('president_dataset') != -1:\n",
    "                     df()\n",
    "              elif func == \"2\" and file_name.find('president_dataset') != -1:\n",
    "                     predict_2()\n",
    "              elif func == \"1\" and file_name.find('senate_dataset') != -1:\n",
    "                     df()\n",
    "              elif func == \"2\" and file_name.find('senate_dataset') != -1:\n",
    "                     nn_1layer()\n",
    "              elif func == \"3\" and file_name.find('senate_dataset') != -1:\n",
    "                     nn_2layers()\n",
    "              elif func == \"4\" and file_name.find('senate_dataset') != -1:\n",
    "                     senate_predict()\n",
    "              elif func == \"1\" and file_name.find('independent_expenditures') != -1:\n",
    "                     df()\n",
    "              elif func == \"2\" and file_name.find('independent_expenditures') != -1:\n",
    "                     expenditures_2()\n",
    "              elif func == \"3\" and file_name.find('independent_expenditures') != -1:\n",
    "                     expenditures_3()\n",
    "              elif func == \"4\" and file_name.find('independent_expenditures') != -1:\n",
    "                     expenditures_4()\n",
    "              elif func == \"5\" and file_name.find('independent_expenditures') != -1:\n",
    "                     expenditures_5()\n",
    "              elif func == \"6\" and file_name.find('independent_expenditures') != -1:\n",
    "                     expenditures_6()\n",
    "              elif func == \"7\" and file_name.find('independent_expenditures') != -1:\n",
    "                     r2_2layers()\n",
    "              elif func == \"1\" and file_name.find('epi') != -1:\n",
    "                     df()\n",
    "              elif func == \"2\" and file_name.find('epi') != -1:\n",
    "                     epi2()\n",
    "              elif func == \"3\" and file_name.find('epi') != -1:\n",
    "                     epi3()\n",
    "              elif func == \"4\" and file_name.find('epi') != -1:\n",
    "                     epi4()\n",
    "              elif func == \"5\" and file_name.find('epi') != -1:\n",
    "                     epi5()\n",
    "              elif func == \"6\" and file_name.find('epi') != -1:\n",
    "                     epi6()\n",
    "              if func == \"1\" and file_name.find('swing_state') != -1:\n",
    "                     df()\n",
    "              elif func == \"2\" and file_name.find('swing_state') != -1:\n",
    "                     swing_state_2()\n",
    "              elif func == \"3\" and file_name.find('swing_state') != -1:\n",
    "                     swing_state_3()\n",
    "              elif func == \"1\" and file_name.find('Georgia') != -1:\n",
    "                     df()\n",
    "              elif func == \"2\" and file_name.find('Georgia') != -1:\n",
    "                     georgia_2()\n",
    "              elif func == \"3\" and file_name.find('Georgia') != -1:\n",
    "                     georgia_3()\n",
    "              elif func == \"4\" and file_name.find('Georgia') != -1:\n",
    "                     georgia_4()\n",
    "              elif func == \"5\" and file_name.find('Georgia') != -1:\n",
    "                     georgia_5()\n",
    "              elif func == \"6\" and file_name.find('Georgia') != -1:\n",
    "                     georgia_6()\n",
    "             \n",
    "              \n",
    "              plt.show()\n",
    "              plt.close()\n",
    " "
   ]
  }
 ]
}