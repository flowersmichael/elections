{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python379jvsc74a57bd086788b88977cb793ff7959ddc9fc7a2d79c7f0e4f7b79c52c18afcedbe69e051",
   "display_name": "Python 3.7.9 64-bit ('PythonData': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "86788b88977cb793ff7959ddc9fc7a2d79c7f0e4f7b79c52c18afcedbe69e051"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.colors as mcolors\n",
    "import pandas as pd \n",
    "import plotly as py\n",
    "import math\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from itertools import cycle, islice\n",
    "from sklearn.linear_model import LinearRegression, BayesianRidge\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import datetime\n",
    "import operator \n",
    "from simple_colors import *\n",
    "import colorama\n",
    "from colorama import Fore\n",
    "plt.style.use('fivethirtyeight')\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('retina')\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "import plotly.express as px\n",
    "import csv\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import os.path\n",
    "from pathlib import Path\n",
    "import fnmatch\n",
    "from simple_colors import * # pip install simple-colors\n",
    "import warnings #fixed any warning in terminal\n",
    "from pandas.api.types import is_string_dtype\n",
    "from pandas.api.types import is_numeric_dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_2layers():\n",
    "    df = pd.read_csv(csv_file)\n",
    "    #Create category_columns and numeric_columns variables\n",
    "    numeric_columns = []\n",
    "    category_columns = []\n",
    "    for col in df.columns:\n",
    "        if is_string_dtype(df[col]) == True:\n",
    "            category_columns.append(col)\n",
    "        elif is_numeric_dtype(df[col]) == True:\n",
    "            numeric_columns.append(col)\n",
    "    #Create dummy variables for the category_columns and merge on the numeric_columns to create an X dataset\n",
    "    category_columns = pd.get_dummies(df[category_columns])\n",
    "    X = df[numeric_columns].merge(category_columns, left_index= True, right_index= True)\n",
    "    #Create an y dataset\n",
    "    y = df['totalvotes'].values\n",
    "    # Split X and y into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "    # Scale X_train and X_test\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.fit_transform(X_test)\n",
    "\n",
    "    # Create a neural network model with keras\n",
    "    nn = tf.keras.models.Sequential()\n",
    "    # Add a hidden layer with twice as many neurons as there are inputs. Use 'relu'\n",
    "    n_input = len(X_train_scaled[0])\n",
    "\n",
    "    n_hidden = n_input * 2\n",
    "    n_hidden_layer2 = n_input * 2 #2nd hidden layer\n",
    "\n",
    "    nn.add(tf.keras.layers.Dense(units=n_hidden, input_dim=n_input, activation='relu'))\n",
    "    nn.add(tf.keras.layers.Dense(units=n_hidden_layer2, activation='relu')) #2nd hidden layer\n",
    "\n",
    "    # add an output layer with a 'linear' activation function.\n",
    "    nn.add(tf.keras.layers.Dense(units=1,  activation='linear'))\n",
    "    # print a summary of the model\n",
    "    print(nn.summary())\n",
    "    # compile the model using the \"adam\" optimizer and \"mean_squared_error\" loss function\n",
    "    nn.compile(loss='mean_squared_error' , optimizer='adam' , metrics=['mse'])\n",
    "    # train the model for 100 epochs\n",
    "    model = nn.fit(X_train_scaled, y_train, epochs=100)\n",
    "    # predict values for the train and test sets\n",
    "    y_train_pred = nn.predict(X_train_scaled)\n",
    "    y_test_pred = nn.predict(X_test_scaled)\n",
    "    # score the training predictions with r2_score()\n",
    "    print(f\"r2_score of y_train: {r2_score(y_train, y_train_pred)}\")\n",
    "    # score the test predictions with r2_score()\n",
    "    print(f\"r2_score of y_test: {r2_score(y_test, y_test_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_1layer():\n",
    "    df = pd.read_csv(csv_file)\n",
    "    #Create category_columns and numeric_columns variables\n",
    "    numeric_columns = []\n",
    "    category_columns = []\n",
    "    for col in df.columns:\n",
    "        if is_string_dtype(df[col]) == True:\n",
    "            category_columns.append(col)\n",
    "        elif is_numeric_dtype(df[col]) == True:\n",
    "            numeric_columns.append(col)\n",
    "    #Create dummy variables for the category_columns and merge on the numeric_columns to create an X dataset\n",
    "    category_columns = pd.get_dummies(df[category_columns])\n",
    "    X = df[numeric_columns].merge(category_columns, left_index= True, right_index= True)\n",
    "    #Create an y dataset\n",
    "    y = df['totalvotes'].values\n",
    "    # Split X and y into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "    # Scale X_train and X_test\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.fit_transform(X_test)\n",
    "\n",
    "    # Create a neural network model with keras\n",
    "    nn = tf.keras.models.Sequential()\n",
    "    # Add a hidden layer with twice as many neurons as there are inputs. Use 'relu'\n",
    "    n_input = len(X_train_scaled[0])\n",
    "\n",
    "    n_hidden = n_input * 2\n",
    "    #n_hidden_layer2 = n_input * 2 #2nd hidden layer\n",
    "\n",
    "    nn.add(tf.keras.layers.Dense(units=n_hidden, input_dim=n_input, activation='relu'))\n",
    "    #nn.add(tf.keras.layers.Dense(units=n_hidden_layer2, activation='relu')) #2nd hidden layer\n",
    "\n",
    "    # add an output layer with a 'linear' activation function.\n",
    "    nn.add(tf.keras.layers.Dense(units=1,  activation='linear'))\n",
    "    # print a summary of the model\n",
    "    print(nn.summary())\n",
    "    # compile the model using the \"adam\" optimizer and \"mean_squared_error\" loss function\n",
    "    nn.compile(loss='mean_squared_error' , optimizer='adam' , metrics=['mse'])\n",
    "    # train the model for 100 epochs\n",
    "    model = nn.fit(X_train_scaled, y_train, epochs=100)\n",
    "    # predict values for the train and test sets\n",
    "    y_train_pred = nn.predict(X_train_scaled)\n",
    "    y_test_pred = nn.predict(X_test_scaled)\n",
    "    # score the training predictions with r2_score()\n",
    "    print(f\"r2_score of y_train: {r2_score(y_train, y_train_pred)}\")\n",
    "    # score the test predictions with r2_score()\n",
    "    print(f\"r2_score of y_test: {r2_score(y_test, y_test_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_2():\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    df = pd.read_csv(csv_file)\n",
    "    df = df[df.loc[:] != 'LIB'].dropna()\n",
    "    df = df.drop(df.columns[0], axis=1)\n",
    "    df.party = df.party.replace({'DEM': 1, 'REP': 2})\n",
    "    dataset = df.drop(['state', 'party'],axis=1)\n",
    "    # the last column is our label\n",
    "    y_train = dataset.iloc[:,-1:]\n",
    "    #drop last column of data\n",
    "    X_train = dataset.iloc[:, :-1]\n",
    "    #drop first colum of data\n",
    "    X_test = dataset.iloc[:,1:]\n",
    "    model = RandomForestRegressor(max_depth=5, random_state=1, n_estimators=1000).fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_train)\n",
    "    print(y_pred)\n",
    "    print(f\"Predict_Score: {model.score(X_train, y_train)}\")\n",
    "    prediction = pd.DataFrame({'state':df.state,'party':df.party, 'prediction_2024': y_pred.astype(int)})\n",
    "    my_colors = list(islice(cycle(['b', 'r']), None, len(prediction)))\n",
    "    prediction.party = prediction.party.map({1: 'DEM', 2: 'REP'})\n",
    "    prediction.groupby('party')['prediction_2024'].sum().plot.bar(ylabel= \"candidatevotes\", title=\"2024 Party Prediction\", color=my_colors)\n",
    "    predict_winner = prediction.groupby('party')['prediction_2024'].sum()\n",
    "    print(predict_winner)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minority_2(): \n",
    "    import plotly.figure_factory as ff\n",
    "    import numpy as np \n",
    "    import pandas as pd\n",
    "    import plotly as py\n",
    "\n",
    "    NE_states = ['Georgia', 'South Carolina']\n",
    "    df = pd.read_csv(csv_file)\n",
    "    df = df[df['STNAME'].isin(NE_states)]\n",
    "\n",
    "    values = df['TOT_POP'].tolist()\n",
    "    fips = df['FIPS'].tolist()\n",
    "    count=df['Black'].tolist()\n",
    "\n",
    "    color = [\"#8dd3c7\", \"#ffffb3\", \"#bebada\", \"#fb8072\",\n",
    "                \"#80b1d3\", \"#fdb462\", \"#b3de69\", \"#fccde5\",\n",
    "                \"#d9d9d9\", \"#bc80bd\", \"#ccebc5\", \"#ffed6f\",\n",
    "                \"#8dd3c7\", \"#ffffb3\", \"#bebada\", \"#fb8072\",\n",
    "                \"#80b1d3\", \"#fdb462\", \"#b3de69\", \"#fccde5\",\n",
    "                \"#d9d9d9\", \"#bc80bd\", \"#ccebc5\", \"#ffed6f\",\n",
    "                \"#8dd3c7\", \"#ffffb3\", \"#bebada\", \"#fb8072\",\n",
    "                \"#80b1d3\", \"#fdb462\", \"#b3de69\", \"#fccde5\",\n",
    "                \"#d9d9d9\", \"#bc80bd\", \"#ccebc5\", \"#ffed6f\"]\n",
    "    colorscale = color * 6\n",
    "\n",
    "    fig = ff.create_choropleth(\n",
    "        fips=fips, values=values,\n",
    "        #colorscale=colorscale, round_legend_values=True,\n",
    "        simplify_county=0, simplify_state=0,\n",
    "        scope=NE_states, county_outline={'color': 'rgb(255,255,255)', 'width': 0.5},\n",
    "        state_outline={'color': 'rgb(0,0,0)', 'width': 2},\n",
    "        #show_hover=True, centroid_marker={'opacity': 1},\n",
    "        legend_title='Population per county',\n",
    "        title='Georgia vs South Carolina Population'\n",
    "\n",
    "    )\n",
    "\n",
    "    fig.layout.template = None\n",
    "    fig.show()\n",
    "    py.offline.plot(fig,\n",
    "    filename='Georgia vs South Carolina.html',\n",
    "    include_plotlyjs='https://cdn.plot.ly/plotly-1.42.3.min.js')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def county_4():\n",
    "    from urllib.request import urlopen\n",
    "    import plotly as py\n",
    "    import json\n",
    "    import webbrowser\n",
    "    df = pd.read_csv(csv_file)\n",
    "    #df['fips'] = df['fips'].apply(lambda x: '0'+x if len(x) == 4 else x)\n",
    "    with urlopen('https://raw.githubusercontent.com/plotly/datasets/master/geojson-counties-fips.json') as response:\n",
    "        counties = json.load(response)\n",
    "    #geojson = px.data.election_geojson()\n",
    "    #df = counties_fips_color[(counties_fips_color[\"state_code\"] == \"GA\") | (counties_fips_color[\"state_code\"] == \"FL\")]\n",
    "    states = ['GA', 'SC', 'FL']\n",
    "    df = df[df[\"state_code\"].isin(states)]\n",
    "    #df = counties_fips_color\n",
    "    fig = px.choropleth(df, geojson=counties, locations='fips', color='color',\n",
    "                                scope=\"usa\",\n",
    "                            \n",
    "                            hover_data=[\"state\",\"county\", \"candidate\", \"total_votes\"])\n",
    "    fig.update_geos(\n",
    "                #lonaxis_range=[20, 380],\n",
    "                projection_scale=2.7,\n",
    "                center=dict(lat=31, lon=-83),\n",
    "                visible=True)                      \n",
    "    fig.update_layout(title= {\"text\": \"Georgia vs South Carolina & Florida'\\n' 2020 swing states total_votes\", \"xanchor\": \"center\", \"x\": 0.5, \"y\": 0.95}, \n",
    "        margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0}, showlegend=False)\n",
    "    fig.show()\n",
    "    fig.write_html(\"myplot.html\")\n",
    "    url = 'file://file:///Users/hiep_pham/Desktop/Analysis_Projects/Final_Project/myplot.html'\n",
    "    webbrowser.open(url, new=2)  # open in new tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def county_3():\n",
    "    df = pd.read_csv(csv_file)\n",
    "    plt.scatter(df.median_age,df.total_votes)\n",
    "    plt.xlabel(\"median_age\")\n",
    "    plt.ylabel('Total_Votes')\n",
    "    plt.title(\"median_age vs Total_Votes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def county_2():\n",
    "    df = pd.read_csv(csv_file)\n",
    "    y = df.total_votes\n",
    "    X = df.population.values.reshape(-1, 1)\n",
    "    model = LinearRegression().fit(X, y)\n",
    "    y_pred = model.predict(X)\n",
    "    plt.scatter(X,y)\n",
    "    plt.plot(X, y_pred, color='red')\n",
    "    plt.xlabel(\"Population\")\n",
    "    plt.ylabel('Total_Votes')\n",
    "    plt.title(\"Population vs Total_Votes'\\n' Linear Regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_3():\n",
    "    df = pd.read_csv(csv_file)\n",
    "    df = df[['year','House winner spending', 'Senate winner spending']] \n",
    "    df = df.sort_values(by='year', ascending=True)\n",
    "    df.plot(\n",
    "    x = 'year', \n",
    "    kind = 'barh', \n",
    "    stacked = True, \n",
    "    title = 'House winner vs. Senate winner Spending',)\n",
    "    plt.xlabel('Spending')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_2():\n",
    "    df = pd.read_csv(csv_file)\n",
    "    df = df[['year','Democrats', 'Republicans']] \n",
    "    df = df.sort_values(by='year', ascending=True)\n",
    "    df.plot(\n",
    "    x = 'year', \n",
    "    kind = 'barh', \n",
    "    stacked = True, \n",
    "    title = 'Democrats vs. Republican Spending',)\n",
    "    plt.xlabel('Spending')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df():\n",
    "    df = pd.read_csv(csv_file)\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    plt.close()\n",
    "    csv_file = input(\"Import CSV_file to analyze: \").strip()\n",
    "    file_name1 = os.path.split(os.path.abspath(csv_file))[-1] \n",
    "    if len(csv_file) < 2: #hit enter to quit csv files while loop(enter is len = 1) \n",
    "        break  \n",
    "    elif not file_name1.endswith('csv'):\n",
    "        continue  # ignore it if not csv files\n",
    "    file_name, file_extension = os.path.splitext(file_name1)   \n",
    "    list1 = [\"Option 1: Print Data Frame\",\n",
    "             \"Option 2: Democrats vs. Republican Spending\",\n",
    "             \"Option 3: House winner vs. Senate winner Spending\"\n",
    "            ]\n",
    "    list2 = [\"Option 1: Print Data Frame\",\n",
    "             \"Option 2: Population vs Total_Votes & Linear Regression\",\n",
    "             \"Option 3: Median Age vs Total_Votes\",\n",
    "             \"Option 4: 2020 swing states total_votes(Georgia vs South Carolina & Florida)\",\n",
    "            ]\n",
    "    list3 = [\"Option 1: Print Data Frame\",\n",
    "             \"Option 2: Georgia vs South Carolina Population\",\n",
    "            ]\n",
    "    list4 = [\"Option 1: Print Data Frame\",\n",
    "             \"Option 2: 2024 Party Prediction (Randomforestclassifier)\",\n",
    "            ]\n",
    "    list5 = [\"Option 1: Print Data Frame\",\n",
    "             \"Option 2: neural network with 1 hidden layer\",\n",
    "             \"Option 3: neural network with 2 hidden layers\",\n",
    "            ]\n",
    "    while True and len(file_name) > 3:\n",
    "        if file_name.find('CostOf') != -1:\n",
    "            print(blue(f\"The following options are available for {file_name1}:\"))\n",
    "            print(*list1,sep='\\n')\n",
    "            func = input(\"Please input the option #: \")\n",
    "            print(\"\")\n",
    "        elif file_name.find('president_counties') != -1:\n",
    "            print(blue(f\"The following options are available for {file_name1}:\"))\n",
    "            print(*list2,sep='\\n')\n",
    "            func = input(\"Please input the option #: \")\n",
    "            print(\"\")\n",
    "        elif file_name.find('minority') != -1:\n",
    "            print(blue(f\"The following options are available for {file_name1}:\"))\n",
    "            print(*list3,sep='\\n')\n",
    "            func = input(\"Please input the option #: \")\n",
    "            print(\"\")\n",
    "        elif file_name.find('president_dataset') != -1:\n",
    "            print(blue(f\"The following options are available for {file_name1}:\"))\n",
    "            print(*list4,sep='\\n')\n",
    "            func = input(\"Please input the option #: \")\n",
    "            print(\"\")\n",
    "        elif file_name.find('senate_dataset') != -1:\n",
    "            print(blue(f\"The following options are available for {file_name1}:\"))\n",
    "            print(*list5,sep='\\n')\n",
    "            func = input(\"Please input the option #: \")\n",
    "            print(\"\")\n",
    "        \n",
    "        if func == \"\": #hit enter to quit function while loop(enter is len = 1) \n",
    "            break\n",
    "        elif func not in (\"1\", \"2\", \"3\", \"4\", \"5\"):\n",
    "             print(red(\"Typo! Please try again.\"))\n",
    "        if func == \"1\" and file_name.find('CostOf') != -1:\n",
    "                df()\n",
    "        elif func == \"2\" and file_name.find('CostOf') != -1:\n",
    "                cost_2()\n",
    "        elif func == \"3\" and file_name.find('CostOf') != -1:\n",
    "                cost_3()\n",
    "        elif func == \"1\" and file_name.find('president_counties') != -1:\n",
    "                df()       \n",
    "        elif func == \"2\" and file_name.find('president_counties') != -1:\n",
    "                county_2()\n",
    "        elif func == \"3\" and file_name.find('president_counties') != -1:\n",
    "                county_3()\n",
    "        elif func == \"4\" and file_name.find('president_counties') != -1:\n",
    "                county_4()\n",
    "        elif func == \"1\" and file_name.find('minority') != -1:\n",
    "               df()\n",
    "        elif func == \"2\" and file_name.find('minority') != -1:\n",
    "               minority_2()\n",
    "        elif func == \"1\" and file_name.find('president_dataset') != -1:\n",
    "               df()\n",
    "        elif func == \"2\" and file_name.find('president_dataset') != -1:\n",
    "               predict_2()\n",
    "        elif func == \"1\" and file_name.find('senate_dataset') != -1:\n",
    "               df()\n",
    "        elif func == \"2\" and file_name.find('senate_dataset') != -1:\n",
    "               nn_1layer()\n",
    "        elif func == \"3\" and file_name.find('senate_dataset') != -1:\n",
    "               nn_2layers()\n",
    "        \n",
    "        plt.show()\n",
    "        plt.close()\n",
    " "
   ]
  }
 ]
}