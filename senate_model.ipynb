{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3710jvsc74a57bd0c10d354e963c3ef3cfe26ce7f2c15db051cec7895d853c3c04a448c95c5a7793",
   "display_name": "Python 3.7.10 64-bit ('tf': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "c10d354e963c3ef3cfe26ce7f2c15db051cec7895d853c3c04a448c95c5a7793"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from pandas.api.types import is_string_dtype\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "import pandas as pd\n",
    "import psycopg2 as pg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      index  Unnamed: 0  year        _state state_code  state_fips  state_cen  \\\n",
       "0         0           0  1976       ARIZONA         AZ           4         86   \n",
       "1         1           1  1976       ARIZONA         AZ           4         86   \n",
       "2         2           2  1976       ARIZONA         AZ           4         86   \n",
       "3         3           3  1976       ARIZONA         AZ           4         86   \n",
       "4         4           4  1976       ARIZONA         AZ           4         86   \n",
       "...     ...         ...   ...           ...        ...         ...        ...   \n",
       "3624   3624        3009  2014  SOUTH DAKOTA         SD          46         45   \n",
       "3625   3625        3248  2016  SOUTH DAKOTA         SD          46         45   \n",
       "3626   3626        3249  2016  SOUTH DAKOTA         SD          46         45   \n",
       "3627   3627        3595  2020  SOUTH DAKOTA         SD          46         45   \n",
       "3628   3628        3596  2020  SOUTH DAKOTA         SD          46         45   \n",
       "\n",
       "      state_ic     office   district  ...            candidate  \\\n",
       "0           61  US SENATE  statewide  ...          SAM STEIGER   \n",
       "1           61  US SENATE  statewide  ...  WM. MATHEWS FEIGHAN   \n",
       "2           61  US SENATE  statewide  ...     DENNIS DECONCINI   \n",
       "3           61  US SENATE  statewide  ...        ALLAN NORWITZ   \n",
       "4           61  US SENATE  statewide  ...            BOB FIELD   \n",
       "...        ...        ...        ...  ...                  ...   \n",
       "3624        37  US SENATE  statewide  ...         RICK WEILAND   \n",
       "3625        37  US SENATE  statewide  ...        JOHN R. THUNE   \n",
       "3626        37  US SENATE  statewide  ...         JAY WILLIAMS   \n",
       "3627        37  US SENATE  statewide  ...          MIKE ROUNDS   \n",
       "3628        37  US SENATE  statewide  ...           DAN AHLERS   \n",
       "\n",
       "      party_detailed writein  _mode  candidatevotes totalvotes  unofficial  \\\n",
       "0         REPUBLICAN   False  total          321236     741210       False   \n",
       "1        INDEPENDENT   False  total            1565     741210       False   \n",
       "2           DEMOCRAT   False  total          400334     741210       False   \n",
       "3        LIBERTARIAN   False  total            7310     741210       False   \n",
       "4        INDEPENDENT   False  total           10765     741210       False   \n",
       "...              ...     ...    ...             ...        ...         ...   \n",
       "3624        DEMOCRAT   False  total           82456     279412       False   \n",
       "3625      REPUBLICAN   False  total          265516     369656       False   \n",
       "3626        DEMOCRAT   False  total          104140     369656       False   \n",
       "3627      REPUBLICAN   False  total          276232     420219        True   \n",
       "3628        DEMOCRAT   False  total          143987     420219        True   \n",
       "\n",
       "      _version  party_simplified  Results  \n",
       "0     20210114        REPUBLICAN        0  \n",
       "1     20210114             OTHER        0  \n",
       "2     20210114          DEMOCRAT        1  \n",
       "3     20210114       LIBERTARIAN        0  \n",
       "4     20210114             OTHER        0  \n",
       "...        ...               ...      ...  \n",
       "3624  20210114          DEMOCRAT        0  \n",
       "3625  20210114        REPUBLICAN        1  \n",
       "3626  20210114          DEMOCRAT        0  \n",
       "3627  20210114        REPUBLICAN        1  \n",
       "3628  20210114          DEMOCRAT        0  \n",
       "\n",
       "[3629 rows x 22 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>Unnamed: 0</th>\n      <th>year</th>\n      <th>_state</th>\n      <th>state_code</th>\n      <th>state_fips</th>\n      <th>state_cen</th>\n      <th>state_ic</th>\n      <th>office</th>\n      <th>district</th>\n      <th>...</th>\n      <th>candidate</th>\n      <th>party_detailed</th>\n      <th>writein</th>\n      <th>_mode</th>\n      <th>candidatevotes</th>\n      <th>totalvotes</th>\n      <th>unofficial</th>\n      <th>_version</th>\n      <th>party_simplified</th>\n      <th>Results</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1976</td>\n      <td>ARIZONA</td>\n      <td>AZ</td>\n      <td>4</td>\n      <td>86</td>\n      <td>61</td>\n      <td>US SENATE</td>\n      <td>statewide</td>\n      <td>...</td>\n      <td>SAM STEIGER</td>\n      <td>REPUBLICAN</td>\n      <td>False</td>\n      <td>total</td>\n      <td>321236</td>\n      <td>741210</td>\n      <td>False</td>\n      <td>20210114</td>\n      <td>REPUBLICAN</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1976</td>\n      <td>ARIZONA</td>\n      <td>AZ</td>\n      <td>4</td>\n      <td>86</td>\n      <td>61</td>\n      <td>US SENATE</td>\n      <td>statewide</td>\n      <td>...</td>\n      <td>WM. MATHEWS FEIGHAN</td>\n      <td>INDEPENDENT</td>\n      <td>False</td>\n      <td>total</td>\n      <td>1565</td>\n      <td>741210</td>\n      <td>False</td>\n      <td>20210114</td>\n      <td>OTHER</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>2</td>\n      <td>1976</td>\n      <td>ARIZONA</td>\n      <td>AZ</td>\n      <td>4</td>\n      <td>86</td>\n      <td>61</td>\n      <td>US SENATE</td>\n      <td>statewide</td>\n      <td>...</td>\n      <td>DENNIS DECONCINI</td>\n      <td>DEMOCRAT</td>\n      <td>False</td>\n      <td>total</td>\n      <td>400334</td>\n      <td>741210</td>\n      <td>False</td>\n      <td>20210114</td>\n      <td>DEMOCRAT</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>3</td>\n      <td>1976</td>\n      <td>ARIZONA</td>\n      <td>AZ</td>\n      <td>4</td>\n      <td>86</td>\n      <td>61</td>\n      <td>US SENATE</td>\n      <td>statewide</td>\n      <td>...</td>\n      <td>ALLAN NORWITZ</td>\n      <td>LIBERTARIAN</td>\n      <td>False</td>\n      <td>total</td>\n      <td>7310</td>\n      <td>741210</td>\n      <td>False</td>\n      <td>20210114</td>\n      <td>LIBERTARIAN</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>4</td>\n      <td>1976</td>\n      <td>ARIZONA</td>\n      <td>AZ</td>\n      <td>4</td>\n      <td>86</td>\n      <td>61</td>\n      <td>US SENATE</td>\n      <td>statewide</td>\n      <td>...</td>\n      <td>BOB FIELD</td>\n      <td>INDEPENDENT</td>\n      <td>False</td>\n      <td>total</td>\n      <td>10765</td>\n      <td>741210</td>\n      <td>False</td>\n      <td>20210114</td>\n      <td>OTHER</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3624</th>\n      <td>3624</td>\n      <td>3009</td>\n      <td>2014</td>\n      <td>SOUTH DAKOTA</td>\n      <td>SD</td>\n      <td>46</td>\n      <td>45</td>\n      <td>37</td>\n      <td>US SENATE</td>\n      <td>statewide</td>\n      <td>...</td>\n      <td>RICK WEILAND</td>\n      <td>DEMOCRAT</td>\n      <td>False</td>\n      <td>total</td>\n      <td>82456</td>\n      <td>279412</td>\n      <td>False</td>\n      <td>20210114</td>\n      <td>DEMOCRAT</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3625</th>\n      <td>3625</td>\n      <td>3248</td>\n      <td>2016</td>\n      <td>SOUTH DAKOTA</td>\n      <td>SD</td>\n      <td>46</td>\n      <td>45</td>\n      <td>37</td>\n      <td>US SENATE</td>\n      <td>statewide</td>\n      <td>...</td>\n      <td>JOHN R. THUNE</td>\n      <td>REPUBLICAN</td>\n      <td>False</td>\n      <td>total</td>\n      <td>265516</td>\n      <td>369656</td>\n      <td>False</td>\n      <td>20210114</td>\n      <td>REPUBLICAN</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3626</th>\n      <td>3626</td>\n      <td>3249</td>\n      <td>2016</td>\n      <td>SOUTH DAKOTA</td>\n      <td>SD</td>\n      <td>46</td>\n      <td>45</td>\n      <td>37</td>\n      <td>US SENATE</td>\n      <td>statewide</td>\n      <td>...</td>\n      <td>JAY WILLIAMS</td>\n      <td>DEMOCRAT</td>\n      <td>False</td>\n      <td>total</td>\n      <td>104140</td>\n      <td>369656</td>\n      <td>False</td>\n      <td>20210114</td>\n      <td>DEMOCRAT</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3627</th>\n      <td>3627</td>\n      <td>3595</td>\n      <td>2020</td>\n      <td>SOUTH DAKOTA</td>\n      <td>SD</td>\n      <td>46</td>\n      <td>45</td>\n      <td>37</td>\n      <td>US SENATE</td>\n      <td>statewide</td>\n      <td>...</td>\n      <td>MIKE ROUNDS</td>\n      <td>REPUBLICAN</td>\n      <td>False</td>\n      <td>total</td>\n      <td>276232</td>\n      <td>420219</td>\n      <td>True</td>\n      <td>20210114</td>\n      <td>REPUBLICAN</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3628</th>\n      <td>3628</td>\n      <td>3596</td>\n      <td>2020</td>\n      <td>SOUTH DAKOTA</td>\n      <td>SD</td>\n      <td>46</td>\n      <td>45</td>\n      <td>37</td>\n      <td>US SENATE</td>\n      <td>statewide</td>\n      <td>...</td>\n      <td>DAN AHLERS</td>\n      <td>DEMOCRAT</td>\n      <td>False</td>\n      <td>total</td>\n      <td>143987</td>\n      <td>420219</td>\n      <td>True</td>\n      <td>20210114</td>\n      <td>DEMOCRAT</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>3629 rows × 22 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "df = 'senate_model'\n",
    "engine = pg.connect(\"dbname='postgres' user='postgres' host='elections.c8frdoyd7uok.us-east-2.rds.amazonaws.com' port='5432' password='Flowers89!'\")\n",
    "df = pd.read_sql(f'select * from {df}', con=engine)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['index', 'Unnamed: 0', 'year', 'state_fips', 'state_cen', 'state_ic', 'special', 'writein', 'candidatevotes', 'totalvotes', 'unofficial', '_version', 'Results']\n['_state', 'state_code', 'office', 'district', 'stage', 'candidate', 'party_detailed', '_mode', 'party_simplified']\n"
     ]
    }
   ],
   "source": [
    "# Create category_columns and numeric_columns variables\n",
    "numeric_columns = []\n",
    "category_columns = []\n",
    "for col in df.columns:\n",
    "    if is_string_dtype(df[col]) == True:\n",
    "        category_columns.append(col)\n",
    "    elif is_numeric_dtype(df[col]) == True:\n",
    "        numeric_columns.append(col)\n",
    "print(numeric_columns)\n",
    "print(category_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      index  Unnamed: 0  year  state_fips  state_cen  state_ic  special  \\\n",
       "0         0           0  1976           4         86        61    False   \n",
       "1         1           1  1976           4         86        61    False   \n",
       "2         2           2  1976           4         86        61    False   \n",
       "3         3           3  1976           4         86        61    False   \n",
       "4         4           4  1976           4         86        61    False   \n",
       "...     ...         ...   ...         ...        ...       ...      ...   \n",
       "3624   3624        3009  2014          46         45        37    False   \n",
       "3625   3625        3248  2016          46         45        37    False   \n",
       "3626   3626        3249  2016          46         45        37    False   \n",
       "3627   3627        3595  2020          46         45        37    False   \n",
       "3628   3628        3596  2020          46         45        37    False   \n",
       "\n",
       "      writein  candidatevotes  totalvotes  ...  party_detailed_WORKERS  \\\n",
       "0       False          321236      741210  ...                       0   \n",
       "1       False            1565      741210  ...                       0   \n",
       "2       False          400334      741210  ...                       0   \n",
       "3       False            7310      741210  ...                       0   \n",
       "4       False           10765      741210  ...                       0   \n",
       "...       ...             ...         ...  ...                     ...   \n",
       "3624    False           82456      279412  ...                       0   \n",
       "3625    False          265516      369656  ...                       0   \n",
       "3626    False          104140      369656  ...                       0   \n",
       "3627    False          276232      420219  ...                       0   \n",
       "3628    False          143987      420219  ...                       0   \n",
       "\n",
       "      party_detailed_WORKERS AGAINST CONCESSIONS  \\\n",
       "0                                              0   \n",
       "1                                              0   \n",
       "2                                              0   \n",
       "3                                              0   \n",
       "4                                              0   \n",
       "...                                          ...   \n",
       "3624                                           0   \n",
       "3625                                           0   \n",
       "3626                                           0   \n",
       "3627                                           0   \n",
       "3628                                           0   \n",
       "\n",
       "      party_detailed_WORKERS LEAGUE  party_detailed_WORKERS WORLD  \\\n",
       "0                                 0                             0   \n",
       "1                                 0                             0   \n",
       "2                                 0                             0   \n",
       "3                                 0                             0   \n",
       "4                                 0                             0   \n",
       "...                             ...                           ...   \n",
       "3624                              0                             0   \n",
       "3625                              0                             0   \n",
       "3626                              0                             0   \n",
       "3627                              0                             0   \n",
       "3628                              0                             0   \n",
       "\n",
       "      party_detailed_WORKING FAMILIES  _mode_total  party_simplified_DEMOCRAT  \\\n",
       "0                                   0            1                          0   \n",
       "1                                   0            1                          0   \n",
       "2                                   0            1                          1   \n",
       "3                                   0            1                          0   \n",
       "4                                   0            1                          0   \n",
       "...                               ...          ...                        ...   \n",
       "3624                                0            1                          1   \n",
       "3625                                0            1                          0   \n",
       "3626                                0            1                          1   \n",
       "3627                                0            1                          0   \n",
       "3628                                0            1                          1   \n",
       "\n",
       "      party_simplified_LIBERTARIAN  party_simplified_OTHER  \\\n",
       "0                                0                       0   \n",
       "1                                0                       1   \n",
       "2                                0                       0   \n",
       "3                                1                       0   \n",
       "4                                0                       1   \n",
       "...                            ...                     ...   \n",
       "3624                             0                       0   \n",
       "3625                             0                       0   \n",
       "3626                             0                       0   \n",
       "3627                             0                       0   \n",
       "3628                             0                       0   \n",
       "\n",
       "      party_simplified_REPUBLICAN  \n",
       "0                               1  \n",
       "1                               0  \n",
       "2                               0  \n",
       "3                               0  \n",
       "4                               0  \n",
       "...                           ...  \n",
       "3624                            0  \n",
       "3625                            1  \n",
       "3626                            0  \n",
       "3627                            1  \n",
       "3628                            0  \n",
       "\n",
       "[3629 rows x 2673 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>Unnamed: 0</th>\n      <th>year</th>\n      <th>state_fips</th>\n      <th>state_cen</th>\n      <th>state_ic</th>\n      <th>special</th>\n      <th>writein</th>\n      <th>candidatevotes</th>\n      <th>totalvotes</th>\n      <th>...</th>\n      <th>party_detailed_WORKERS</th>\n      <th>party_detailed_WORKERS AGAINST CONCESSIONS</th>\n      <th>party_detailed_WORKERS LEAGUE</th>\n      <th>party_detailed_WORKERS WORLD</th>\n      <th>party_detailed_WORKING FAMILIES</th>\n      <th>_mode_total</th>\n      <th>party_simplified_DEMOCRAT</th>\n      <th>party_simplified_LIBERTARIAN</th>\n      <th>party_simplified_OTHER</th>\n      <th>party_simplified_REPUBLICAN</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1976</td>\n      <td>4</td>\n      <td>86</td>\n      <td>61</td>\n      <td>False</td>\n      <td>False</td>\n      <td>321236</td>\n      <td>741210</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1976</td>\n      <td>4</td>\n      <td>86</td>\n      <td>61</td>\n      <td>False</td>\n      <td>False</td>\n      <td>1565</td>\n      <td>741210</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>2</td>\n      <td>1976</td>\n      <td>4</td>\n      <td>86</td>\n      <td>61</td>\n      <td>False</td>\n      <td>False</td>\n      <td>400334</td>\n      <td>741210</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>3</td>\n      <td>1976</td>\n      <td>4</td>\n      <td>86</td>\n      <td>61</td>\n      <td>False</td>\n      <td>False</td>\n      <td>7310</td>\n      <td>741210</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>4</td>\n      <td>1976</td>\n      <td>4</td>\n      <td>86</td>\n      <td>61</td>\n      <td>False</td>\n      <td>False</td>\n      <td>10765</td>\n      <td>741210</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3624</th>\n      <td>3624</td>\n      <td>3009</td>\n      <td>2014</td>\n      <td>46</td>\n      <td>45</td>\n      <td>37</td>\n      <td>False</td>\n      <td>False</td>\n      <td>82456</td>\n      <td>279412</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3625</th>\n      <td>3625</td>\n      <td>3248</td>\n      <td>2016</td>\n      <td>46</td>\n      <td>45</td>\n      <td>37</td>\n      <td>False</td>\n      <td>False</td>\n      <td>265516</td>\n      <td>369656</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3626</th>\n      <td>3626</td>\n      <td>3249</td>\n      <td>2016</td>\n      <td>46</td>\n      <td>45</td>\n      <td>37</td>\n      <td>False</td>\n      <td>False</td>\n      <td>104140</td>\n      <td>369656</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3627</th>\n      <td>3627</td>\n      <td>3595</td>\n      <td>2020</td>\n      <td>46</td>\n      <td>45</td>\n      <td>37</td>\n      <td>False</td>\n      <td>False</td>\n      <td>276232</td>\n      <td>420219</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3628</th>\n      <td>3628</td>\n      <td>3596</td>\n      <td>2020</td>\n      <td>46</td>\n      <td>45</td>\n      <td>37</td>\n      <td>False</td>\n      <td>False</td>\n      <td>143987</td>\n      <td>420219</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>3629 rows × 2673 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    " #Create dummy variables for the category_columns and merge on the numeric_columns to create an X dataset\n",
    "category_columns = pd.get_dummies(df[category_columns])\n",
    "category_columns\n",
    "X = df[numeric_columns].merge(category_columns, left_index= True, right_index= True)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([741210, 741210, 741210, ..., 369656, 420219, 420219])"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "y = df['totalvotes'].values\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split X and y into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2673"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "# Scale X_train and X_test\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.fit_transform(X_test)\n",
    "len(X_train_scaled[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a neural network model with keras\n",
    "nn = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 5346)              14295204  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 5347      \n",
      "=================================================================\n",
      "Total params: 14,300,551\n",
      "Trainable params: 14,300,551\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 2721 samples\n",
      "Epoch 1/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 9392873385028.1152 - mse: 9392873275392.0000\n",
      "Epoch 2/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 9389088473654.0039 - mse: 9389086867456.0000\n",
      "Epoch 3/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 9380036063865.7422 - mse: 9380035559424.0000\n",
      "Epoch 4/100\n",
      "2721/2721 [==============================] - 8s 3ms/sample - loss: 9365595619809.7051 - mse: 9365596667904.0000\n",
      "Epoch 5/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 9346091589339.9668 - mse: 9346093154304.0000\n",
      "Epoch 6/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 9321438736542.0605 - mse: 9321442181120.0000\n",
      "Epoch 7/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 9292501927266.8809 - mse: 9292501483520.0000\n",
      "Epoch 8/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 9259214681516.6426 - mse: 9259217584128.0000\n",
      "Epoch 9/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 9221624151994.6133 - mse: 9221622988800.0000\n",
      "Epoch 10/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 9179942049735.5508 - mse: 9179944189952.0000\n",
      "Epoch 11/100\n",
      "2721/2721 [==============================] - 10s 4ms/sample - loss: 9134072761511.4688 - mse: 9134073184256.0000\n",
      "Epoch 12/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 9084150976107.0664 - mse: 9084151529472.0000\n",
      "Epoch 13/100\n",
      "2721/2721 [==============================] - 10s 4ms/sample - loss: 9031333022213.0801 - mse: 9031334756352.0000\n",
      "Epoch 14/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 8974612649590.3574 - mse: 8974612037632.0000\n",
      "Epoch 15/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 8915033850145.0234 - mse: 8915032997888.0000\n",
      "Epoch 16/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 8852976541656.8613 - mse: 8852976173056.0000\n",
      "Epoch 17/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 8788082646862.3721 - mse: 8788083998720.0000\n",
      "Epoch 18/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 8719941381031.5625 - mse: 8719939141632.0000\n",
      "Epoch 19/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 8650064587055.3242 - mse: 8650067279872.0000\n",
      "Epoch 20/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 8578529980574.0605 - mse: 8578529230848.0000\n",
      "Epoch 21/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 8504581560389.9971 - mse: 8504582078464.0000\n",
      "Epoch 22/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 8428786249982.4014 - mse: 8428786286592.0000\n",
      "Epoch 23/100\n",
      "2721/2721 [==============================] - 10s 4ms/sample - loss: 8351574017513.3193 - mse: 8351572819968.0000\n",
      "Epoch 24/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 8273035087117.8291 - mse: 8273033428992.0000\n",
      "Epoch 25/100\n",
      "2721/2721 [==============================] - 11s 4ms/sample - loss: 8192925258009.4961 - mse: 8192924844032.0000\n",
      "Epoch 26/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 8111225466974.0840 - mse: 8111226617856.0000\n",
      "Epoch 27/100\n",
      "2721/2721 [==============================] - 10s 3ms/sample - loss: 8028719624934.1279 - mse: 8028719415296.0000\n",
      "Epoch 28/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 7944400333283.9629 - mse: 7944399224832.0000\n",
      "Epoch 29/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 7859596470713.8135 - mse: 7859596689408.0000\n",
      "Epoch 30/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 7771120301297.9805 - mse: 7771121516544.0000\n",
      "Epoch 31/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 7686439156561.7578 - mse: 7686438518784.0000\n",
      "Epoch 32/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 7601362168412.3896 - mse: 7601361256448.0000\n",
      "Epoch 33/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 7516503795063.9561 - mse: 7516503146496.0000\n",
      "Epoch 34/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 7431048595171.8691 - mse: 7431049445376.0000\n",
      "Epoch 35/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 7346096849153.4111 - mse: 7346095390720.0000\n",
      "Epoch 36/100\n",
      "2721/2721 [==============================] - 8s 3ms/sample - loss: 7260918374306.6699 - mse: 7260918513664.0000\n",
      "Epoch 37/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 7174577196315.3779 - mse: 7174577192960.0000\n",
      "Epoch 38/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 7088643344145.4053 - mse: 7088644816896.0000\n",
      "Epoch 39/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 7003046631605.3916 - mse: 7003047460864.0000\n",
      "Epoch 40/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 6917141802485.6504 - mse: 6917140250624.0000\n",
      "Epoch 41/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 6830628319191.3564 - mse: 6830628012032.0000\n",
      "Epoch 42/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 6744800606576.0527 - mse: 6744799444992.0000\n",
      "Epoch 43/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 6659189774261.4854 - mse: 6659189506048.0000\n",
      "Epoch 44/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 6573029711923.1816 - mse: 6573031161856.0000\n",
      "Epoch 45/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 6487780000839.8799 - mse: 6487781933056.0000\n",
      "Epoch 46/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 6402186049262.2178 - mse: 6402187198464.0000\n",
      "Epoch 47/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 6319505884514.8809 - mse: 6319505932288.0000\n",
      "Epoch 48/100\n",
      "2721/2721 [==============================] - 12s 4ms/sample - loss: 6237497673287.6914 - mse: 6237496279040.0000\n",
      "Epoch 49/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 6153960404155.7900 - mse: 6153959899136.0000\n",
      "Epoch 50/100\n",
      "2721/2721 [==============================] - 11s 4ms/sample - loss: 6071023248826.1904 - mse: 6071023828992.0000\n",
      "Epoch 51/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 5988259728972.9600 - mse: 5988259201024.0000\n",
      "Epoch 52/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 5910486203186.8984 - mse: 5910486319104.0000\n",
      "Epoch 53/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 5835919505125.7510 - mse: 5835919458304.0000\n",
      "Epoch 54/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 5761090767672.1680 - mse: 5761089929216.0000\n",
      "Epoch 55/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 5687156867818.6426 - mse: 5687156408320.0000\n",
      "Epoch 56/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 5614857440784.7461 - mse: 5614856568832.0000\n",
      "Epoch 57/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 5543448567407.5830 - mse: 5543448018944.0000\n",
      "Epoch 58/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 5473130383576.0146 - mse: 5473131560960.0000\n",
      "Epoch 59/100\n",
      "2721/2721 [==============================] - 10s 3ms/sample - loss: 5403246448873.3262 - mse: 5403246592000.0000\n",
      "Epoch 60/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 5334555585947.3311 - mse: 5334555951104.0000\n",
      "Epoch 61/100\n",
      "2721/2721 [==============================] - 10s 4ms/sample - loss: 5266881648613.6572 - mse: 5266881380352.0000\n",
      "Epoch 62/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 5201374743671.2979 - mse: 5201374740480.0000\n",
      "Epoch 63/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 5136211429477.6094 - mse: 5136210460672.0000\n",
      "Epoch 64/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 5072876730392.8379 - mse: 5072876994560.0000\n",
      "Epoch 65/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 5008882425576.0088 - mse: 5008881876992.0000\n",
      "Epoch 66/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 4948200138350.8291 - mse: 4948200259584.0000\n",
      "Epoch 67/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 4888762690411.3486 - mse: 4888763301888.0000\n",
      "Epoch 68/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 4830096740416.7285 - mse: 4830095998976.0000\n",
      "Epoch 69/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 4772020205622.9443 - mse: 4772020617216.0000\n",
      "Epoch 70/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 4716257402482.5928 - mse: 4716256821248.0000\n",
      "Epoch 71/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 4662306519745.2471 - mse: 4662307061760.0000\n",
      "Epoch 72/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 4607335314655.9180 - mse: 4607335989248.0000\n",
      "Epoch 73/100\n",
      "2721/2721 [==============================] - 10s 4ms/sample - loss: 4556995155399.7383 - mse: 4556994379776.0000\n",
      "Epoch 74/100\n",
      "2721/2721 [==============================] - 10s 4ms/sample - loss: 4507501494996.4395 - mse: 4507501592576.0000\n",
      "Epoch 75/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 4459816333632.6348 - mse: 4459815501824.0000\n",
      "Epoch 76/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 4411063601392.0996 - mse: 4411064057856.0000\n",
      "Epoch 77/100\n",
      "2721/2721 [==============================] - 10s 4ms/sample - loss: 4366588573889.4351 - mse: 4366587658240.0000\n",
      "Epoch 78/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 4323613590858.7959 - mse: 4323613343744.0000\n",
      "Epoch 79/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 4280792292445.7070 - mse: 4280792383488.0000\n",
      "Epoch 80/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 4239261409824.9287 - mse: 4239261433856.0000\n",
      "Epoch 81/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 4199584123168.2705 - mse: 4199584628736.0000\n",
      "Epoch 82/100\n",
      "2721/2721 [==============================] - 10s 4ms/sample - loss: 4161296052159.2710 - mse: 4161297186816.0000\n",
      "Epoch 83/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 4124405624857.5908 - mse: 4124406185984.0000\n",
      "Epoch 84/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 4088255194253.1250 - mse: 4088254955520.0000\n",
      "Epoch 85/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 4053744999776.6230 - mse: 4053745008640.0000\n",
      "Epoch 86/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 4020776324257.4468 - mse: 4020776730624.0000\n",
      "Epoch 87/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 3987529188995.9043 - mse: 3987529007104.0000\n",
      "Epoch 88/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 3954080757068.3013 - mse: 3954080219136.0000\n",
      "Epoch 89/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 3924481030192.1704 - mse: 3924480491520.0000\n",
      "Epoch 90/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 3895560408729.3911 - mse: 3895561027584.0000\n",
      "Epoch 91/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 3867589154476.5483 - mse: 3867589214208.0000\n",
      "Epoch 92/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 3840688040919.7324 - mse: 3840687210496.0000\n",
      "Epoch 93/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 3813962605245.4834 - mse: 3813962416128.0000\n",
      "Epoch 94/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 3788638059318.1133 - mse: 3788639043584.0000\n",
      "Epoch 95/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 3763644261610.4546 - mse: 3763644661760.0000\n",
      "Epoch 96/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 3739295149744.3115 - mse: 3739295940608.0000\n",
      "Epoch 97/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 3715640679654.6914 - mse: 3715640852480.0000\n",
      "Epoch 98/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 3692276967510.5562 - mse: 3692276482048.0000\n",
      "Epoch 99/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 3668181707476.8154 - mse: 3668181516288.0000\n",
      "Epoch 100/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 3646407481305.6143 - mse: 3646406262784.0000\n",
      "r2_score of y_train: 0.17118410684202645\n",
      "r2_score of y_test: 0.16925638704649182\n"
     ]
    }
   ],
   "source": [
    "#ONE HIDDEN LAYER\n",
    "n_input = len(X_train_scaled[0])\n",
    "n_hidden = n_input * 2\n",
    "#n_hidden_layer2 = n_input * 2 #2nd hidden layer\n",
    "\n",
    "nn.add(tf.keras.layers.Dense(units=n_hidden, input_dim=n_input, activation='relu'))\n",
    "#nn.add(tf.keras.layers.Dense(units=n_hidden_layer2, activation='relu')) #2nd hidden layer\n",
    "\n",
    "# add an output layer with a 'linear' activation function.\n",
    "nn.add(tf.keras.layers.Dense(units=1,  activation='linear'))\n",
    "# print a summary of the model\n",
    "print(nn.summary())\n",
    "# compile the model using the \"adam\" optimizer and \"mean_squared_error\" loss function\n",
    "nn.compile(loss='mean_squared_error' , optimizer='adam' , metrics=['mse'])\n",
    "# train the model for 100 epochs\n",
    "model = nn.fit(X_train_scaled, y_train, epochs=100)\n",
    "# predict values for the train and test sets\n",
    "y_train_pred = nn.predict(X_train_scaled)\n",
    "y_test_pred = nn.predict(X_test_scaled)\n",
    "# score the training predictions with r2_score()\n",
    "print(f\"r2_score of y_train: {r2_score(y_train, y_train_pred)}\")\n",
    "# score the test predictions with r2_score()\n",
    "print(f\"r2_score of y_test: {r2_score(y_test, y_test_pred)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 5346)              14295204  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 5347      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5346)              10692     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5346)              28585062  \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 5347      \n",
      "=================================================================\n",
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "Total params: 14,300,551\n",
      "Trainable params: 14,300,551\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 2721 samples\n",
      "Epoch 1/100\n",
      "2721/2721 [==============================] - 29s 11ms/sample - loss: 3802292490623.8589 - mse: 3802292289536.0000\n",
      "Epoch 2/100\n",
      "2721/2721 [==============================] - 27s 10ms/sample - loss: 3578236507651.9517 - mse: 3578235715584.0000\n",
      "Epoch 3/100\n",
      "2721/2721 [==============================] - 26s 10ms/sample - loss: 3596314341473.8467 - mse: 3596314476544.0000\n",
      "Epoch 4/100\n",
      "2721/2721 [==============================] - 27s 10ms/sample - loss: 3500155670068.8745 - mse: 3500156125184.0000\n",
      "Epoch 5/100\n",
      "2721/2721 [==============================] - 30s 11ms/sample - loss: 3725886337742.0420 - mse: 3725885702144.0000\n",
      "Epoch 6/100\n",
      "2721/2721 [==============================] - 30s 11ms/sample - loss: 3527192989339.2373 - mse: 3527192870912.0000\n",
      "Epoch 7/100\n",
      "2721/2721 [==============================] - 27s 10ms/sample - loss: 3455154646415.2886 - mse: 3455154388992.0000\n",
      "Epoch 8/100\n",
      "2721/2721 [==============================] - 27s 10ms/sample - loss: 3676377263569.5229 - mse: 3676376662016.0000\n",
      "Epoch 9/100\n",
      "2721/2721 [==============================] - 27s 10ms/sample - loss: 3443327324369.2412 - mse: 3443326189568.0000\n",
      "Epoch 10/100\n",
      "2721/2721 [==============================] - 26s 10ms/sample - loss: 3456095890608.4995 - mse: 3456096010240.0000\n",
      "Epoch 11/100\n",
      "2721/2721 [==============================] - 26s 10ms/sample - loss: 3416369396387.1401 - mse: 3416368611328.0000\n",
      "Epoch 12/100\n",
      "2721/2721 [==============================] - 26s 10ms/sample - loss: 3343506158599.1504 - mse: 3343505424384.0000\n",
      "Epoch 13/100\n",
      "2721/2721 [==============================] - 26s 9ms/sample - loss: 3326468709015.0977 - mse: 3326468423680.0000\n",
      "Epoch 14/100\n",
      "2721/2721 [==============================] - 25s 9ms/sample - loss: 3328736026795.6074 - mse: 3328735444992.0000\n",
      "Epoch 15/100\n",
      "2721/2721 [==============================] - 27s 10ms/sample - loss: 3298631425563.2842 - mse: 3298631090176.0000\n",
      "Epoch 16/100\n",
      "2721/2721 [==============================] - 26s 10ms/sample - loss: 3319525252984.5200 - mse: 3319525539840.0000\n",
      "Epoch 17/100\n",
      "2721/2721 [==============================] - 26s 10ms/sample - loss: 3321047980525.3716 - mse: 3321047285760.0000\n",
      "Epoch 18/100\n",
      "2721/2721 [==============================] - 26s 10ms/sample - loss: 3268057122062.5830 - mse: 3268056973312.0000\n",
      "Epoch 19/100\n",
      "2721/2721 [==============================] - 26s 10ms/sample - loss: 3240656538838.1328 - mse: 3240656896000.0000\n",
      "Epoch 20/100\n",
      "2721/2721 [==============================] - 26s 10ms/sample - loss: 3170409919663.7471 - mse: 3170409906176.0000\n",
      "Epoch 21/100\n",
      "2721/2721 [==============================] - 26s 10ms/sample - loss: 3190678898368.1177 - mse: 3190678618112.0000\n",
      "Epoch 22/100\n",
      "2721/2721 [==============================] - 26s 10ms/sample - loss: 3164824871703.8032 - mse: 3164825452544.0000\n",
      "Epoch 23/100\n",
      "2721/2721 [==============================] - 30s 11ms/sample - loss: 3145498906953.6670 - mse: 3145499410432.0000\n",
      "Epoch 24/100\n",
      "2721/2721 [==============================] - 27s 10ms/sample - loss: 3113732342892.0073 - mse: 3113732276224.0000\n",
      "Epoch 25/100\n",
      "2721/2721 [==============================] - 28s 10ms/sample - loss: 3085170290478.7593 - mse: 3085170376704.0000\n",
      "Epoch 26/100\n",
      "2721/2721 [==============================] - 26s 9ms/sample - loss: 3081164903283.6284 - mse: 3081164029952.0000\n",
      "Epoch 27/100\n",
      "2721/2721 [==============================] - 26s 10ms/sample - loss: 3041561595508.8511 - mse: 3041561935872.0000\n",
      "Epoch 28/100\n",
      "2721/2721 [==============================] - 27s 10ms/sample - loss: 3045653991494.7505 - mse: 3045653741568.0000\n",
      "Epoch 29/100\n",
      "2721/2721 [==============================] - 26s 9ms/sample - loss: 3005187546296.0264 - mse: 3005188145152.0000\n",
      "Epoch 30/100\n",
      "2721/2721 [==============================] - 26s 9ms/sample - loss: 2984007215015.9385 - mse: 2984007696384.0000\n",
      "Epoch 31/100\n",
      "2721/2721 [==============================] - 26s 10ms/sample - loss: 2949871529564.0132 - mse: 2949870780416.0000\n",
      "Epoch 32/100\n",
      "2721/2721 [==============================] - 27s 10ms/sample - loss: 2920725089868.9600 - mse: 2920725610496.0000\n",
      "Epoch 33/100\n",
      "2721/2721 [==============================] - 26s 10ms/sample - loss: 3127785441285.2686 - mse: 3127785553920.0000\n",
      "Epoch 34/100\n",
      "2721/2721 [==============================] - 26s 10ms/sample - loss: 2873434355526.0918 - mse: 2873434308608.0000\n",
      "Epoch 35/100\n",
      "2721/2721 [==============================] - 26s 9ms/sample - loss: 2835891068744.3496 - mse: 2835890831360.0000\n",
      "Epoch 36/100\n",
      "2721/2721 [==============================] - 26s 9ms/sample - loss: 2831345018810.0024 - mse: 2831345516544.0000\n",
      "Epoch 37/100\n",
      "2721/2721 [==============================] - 26s 10ms/sample - loss: 2784359049718.0273 - mse: 2784358301696.0000\n",
      "Epoch 38/100\n",
      "2721/2721 [==============================] - 26s 9ms/sample - loss: 2789143103938.8462 - mse: 2789142953984.0000\n",
      "Epoch 39/100\n",
      "2721/2721 [==============================] - 186s 68ms/sample - loss: 2809799787453.3892 - mse: 2809800163328.0000\n",
      "Epoch 40/100\n",
      "2721/2721 [==============================] - 31s 12ms/sample - loss: 2724194855112.9614 - mse: 2724194942976.0000\n",
      "Epoch 41/100\n",
      "2721/2721 [==============================] - 30s 11ms/sample - loss: 2682743490222.0537 - mse: 2682742898688.0000\n",
      "Epoch 42/100\n",
      "2721/2721 [==============================] - 30s 11ms/sample - loss: 2672172022742.2271 - mse: 2672172466176.0000\n",
      "Epoch 43/100\n",
      "2721/2721 [==============================] - 27s 10ms/sample - loss: 2636723484227.1753 - mse: 2636723519488.0000\n",
      "Epoch 44/100\n",
      "2721/2721 [==============================] - 27s 10ms/sample - loss: 2691450874430.2827 - mse: 2691450798080.0000\n",
      "Epoch 45/100\n",
      "2721/2721 [==============================] - 26s 10ms/sample - loss: 2576564385828.8804 - mse: 2576564879360.0000\n",
      "Epoch 46/100\n",
      "2721/2721 [==============================] - 27s 10ms/sample - loss: 2557169760329.0083 - mse: 2557169631232.0000\n",
      "Epoch 47/100\n",
      "2721/2721 [==============================] - 27s 10ms/sample - loss: 2533286039905.7524 - mse: 2533285953536.0000\n",
      "Epoch 48/100\n",
      "2721/2721 [==============================] - 27s 10ms/sample - loss: 2499937696057.8613 - mse: 2499937304576.0000\n",
      "Epoch 49/100\n",
      "2721/2721 [==============================] - 26s 9ms/sample - loss: 2466012012661.4155 - mse: 2466011676672.0000\n",
      "Epoch 50/100\n",
      "2721/2721 [==============================] - 26s 10ms/sample - loss: 2450598932619.9956 - mse: 2450599182336.0000\n",
      "Epoch 51/100\n",
      "2721/2721 [==============================] - 26s 10ms/sample - loss: 2424131281982.8477 - mse: 2424131289088.0000\n",
      "Epoch 52/100\n",
      "2721/2721 [==============================] - 26s 10ms/sample - loss: 2377976626049.9287 - mse: 2377977167872.0000\n",
      "Epoch 53/100\n",
      "2721/2721 [==============================] - 26s 9ms/sample - loss: 2375465234361.2495 - mse: 2375465566208.0000\n",
      "Epoch 54/100\n",
      "2721/2721 [==============================] - 27s 10ms/sample - loss: 2328893981937.0410 - mse: 2328894111744.0000\n",
      "Epoch 55/100\n",
      "2721/2721 [==============================] - 27s 10ms/sample - loss: 2291925251928.1558 - mse: 2291925254144.0000\n",
      "Epoch 56/100\n",
      "2721/2721 [==============================] - 27s 10ms/sample - loss: 2270920224606.9297 - mse: 2270920441856.0000\n",
      "Epoch 57/100\n",
      "2721/2721 [==============================] - 27s 10ms/sample - loss: 2221644523805.2598 - mse: 2221644447744.0000\n",
      "Epoch 58/100\n",
      "2721/2721 [==============================] - 26s 10ms/sample - loss: 2197541709717.8743 - mse: 2197541617664.0000\n",
      "Epoch 59/100\n",
      "2721/2721 [==============================] - 26s 10ms/sample - loss: 2193568898659.5400 - mse: 2193568956416.0000\n",
      "Epoch 60/100\n",
      "2721/2721 [==============================] - 27s 10ms/sample - loss: 2115602102326.9446 - mse: 2115601825792.0000\n",
      "Epoch 61/100\n",
      "2721/2721 [==============================] - 26s 10ms/sample - loss: 2112293067032.7439 - mse: 2112294092800.0000\n",
      "Epoch 62/100\n",
      "2721/2721 [==============================] - 30s 11ms/sample - loss: 2096182610309.1274 - mse: 2096182591488.0000\n",
      "Epoch 63/100\n",
      "2721/2721 [==============================] - 30s 11ms/sample - loss: 2037058606415.3120 - mse: 2037058764800.0000\n",
      "Epoch 64/100\n",
      "2721/2721 [==============================] - 27s 10ms/sample - loss: 1987896676109.6421 - mse: 1987897065472.0000\n",
      "Epoch 65/100\n",
      "2721/2721 [==============================] - 27s 10ms/sample - loss: 1983944778477.6541 - mse: 1983944982528.0000\n",
      "Epoch 66/100\n",
      "2721/2721 [==============================] - 26s 10ms/sample - loss: 1923850108952.0852 - mse: 1923850174464.0000\n",
      "Epoch 67/100\n",
      "2721/2721 [==============================] - 27s 10ms/sample - loss: 1884373061931.5605 - mse: 1884372860928.0000\n",
      "Epoch 68/100\n",
      "2721/2721 [==============================] - 27s 10ms/sample - loss: 1850879635818.7844 - mse: 1850879901696.0000\n",
      "Epoch 69/100\n",
      "2721/2721 [==============================] - 26s 10ms/sample - loss: 1825544664077.1716 - mse: 1825544601600.0000\n",
      "Epoch 70/100\n",
      "2721/2721 [==============================] - 27s 10ms/sample - loss: 1761428848031.8472 - mse: 1761429291008.0000\n",
      "Epoch 71/100\n",
      "2721/2721 [==============================] - 27s 10ms/sample - loss: 1763147305831.5857 - mse: 1763147382784.0000\n",
      "Epoch 72/100\n",
      "2721/2721 [==============================] - 26s 10ms/sample - loss: 1698973097113.9199 - mse: 1698973220864.0000\n",
      "Epoch 73/100\n",
      "2721/2721 [==============================] - 26s 10ms/sample - loss: 1682542294790.5051 - mse: 1682542166016.0000\n",
      "Epoch 74/100\n",
      "2721/2721 [==============================] - 26s 10ms/sample - loss: 1624590634049.1055 - mse: 1624590778368.0000\n",
      "Epoch 75/100\n",
      "2721/2721 [==============================] - 28s 10ms/sample - loss: 1575240987757.5127 - mse: 1575241121792.0000\n",
      "Epoch 76/100\n",
      "2721/2721 [==============================] - 27s 10ms/sample - loss: 1537420250719.0239 - mse: 1537420034048.0000\n",
      "Epoch 77/100\n",
      "2721/2721 [==============================] - 28s 10ms/sample - loss: 1496402769264.4292 - mse: 1496402624512.0000\n",
      "Epoch 78/100\n",
      "2721/2721 [==============================] - 27s 10ms/sample - loss: 1461933177386.7136 - mse: 1461933178880.0000\n",
      "Epoch 79/100\n",
      "2721/2721 [==============================] - 27s 10ms/sample - loss: 1426711681738.2786 - mse: 1426711773184.0000\n",
      "Epoch 80/100\n",
      "2721/2721 [==============================] - 29s 11ms/sample - loss: 1411330980978.7815 - mse: 1411331260416.0000\n",
      "Epoch 81/100\n",
      "2721/2721 [==============================] - 28s 10ms/sample - loss: 1368692516661.5332 - mse: 1368692752384.0000\n",
      "Epoch 82/100\n",
      "2721/2721 [==============================] - 27s 10ms/sample - loss: 1332359531892.1926 - mse: 1332359331840.0000\n",
      "Epoch 83/100\n",
      "2721/2721 [==============================] - 26s 10ms/sample - loss: 1295595944243.8398 - mse: 1295595995136.0000\n",
      "Epoch 84/100\n",
      "2721/2721 [==============================] - 27s 10ms/sample - loss: 1236748566973.5774 - mse: 1236748599296.0000\n",
      "Epoch 85/100\n",
      "2721/2721 [==============================] - 26s 10ms/sample - loss: 1212441946186.5137 - mse: 1212441952256.0000\n",
      "Epoch 86/100\n",
      "2721/2721 [==============================] - 26s 10ms/sample - loss: 1168972452850.0757 - mse: 1168972840960.0000\n",
      "Epoch 87/100\n",
      "2721/2721 [==============================] - 26s 10ms/sample - loss: 1150564700628.1572 - mse: 1150564696064.0000\n",
      "Epoch 88/100\n",
      "2721/2721 [==============================] - 26s 9ms/sample - loss: 1087914142721.8817 - mse: 1087913787392.0000\n",
      "Epoch 89/100\n",
      "2721/2721 [==============================] - 26s 9ms/sample - loss: 1081953522487.4149 - mse: 1081953222656.0000\n",
      "Epoch 90/100\n",
      "2721/2721 [==============================] - 26s 10ms/sample - loss: 1026947782340.6335 - mse: 1026947809280.0000\n",
      "Epoch 91/100\n",
      "2721/2721 [==============================] - 27s 10ms/sample - loss: 1003273494464.7762 - mse: 1003273519104.0000\n",
      "Epoch 92/100\n",
      "2721/2721 [==============================] - 27s 10ms/sample - loss: 981831638127.7708 - mse: 981831647232.0000\n",
      "Epoch 93/100\n",
      "2721/2721 [==============================] - 26s 9ms/sample - loss: 939003132801.9287 - mse: 939003084800.0000\n",
      "Epoch 94/100\n",
      "2721/2721 [==============================] - 28s 10ms/sample - loss: 922999151580.6248 - mse: 922999062528.0000\n",
      "Epoch 95/100\n",
      "2721/2721 [==============================] - 28s 10ms/sample - loss: 874867335509.7096 - mse: 874867130368.0000\n",
      "Epoch 96/100\n",
      "2721/2721 [==============================] - 26s 9ms/sample - loss: 852282213170.8989 - mse: 852282245120.0000\n",
      "Epoch 97/100\n",
      "2721/2721 [==============================] - 26s 9ms/sample - loss: 815744203805.4950 - mse: 815744352256.0000\n",
      "Epoch 98/100\n",
      "2721/2721 [==============================] - 26s 9ms/sample - loss: 819459720564.9453 - mse: 819459850240.0000\n",
      "Epoch 99/100\n",
      "2721/2721 [==============================] - 26s 9ms/sample - loss: 784448792770.9401 - mse: 784448684032.0000\n",
      "Epoch 100/100\n",
      "2721/2721 [==============================] - 27s 10ms/sample - loss: 760096856696.9908 - mse: 760097013760.0000\n",
      "r2_score of y_train: 0.8335064203625604\n",
      "r2_score of y_test: 0.8135038314125344\n"
     ]
    }
   ],
   "source": [
    "#TWO HIDDEN LAYERS\n",
    "n_input = len(X_train_scaled[0])\n",
    "n_hidden = n_input * 2\n",
    "n_hidden_layer2 = n_input * 2 #2nd hidden layer\n",
    "\n",
    "nn.add(tf.keras.layers.Dense(units=n_hidden, input_dim=n_input, activation='relu'))\n",
    "nn.add(tf.keras.layers.Dense(units=n_hidden_layer2, activation='relu')) #2nd hidden layer\n",
    "\n",
    "# add an output layer with a 'linear' activation function.\n",
    "nn.add(tf.keras.layers.Dense(units=1,  activation='linear'))\n",
    "# print a summary of the model\n",
    "print(nn.summary())\n",
    "# compile the model using the \"adam\" optimizer and \"mean_squared_error\" loss function\n",
    "nn.compile(loss='mean_squared_error' , optimizer='adam' , metrics=['mse'])\n",
    "# train the model for 100 epochs\n",
    "model = nn.fit(X_train_scaled, y_train, epochs=100)\n",
    "# predict values for the train and test sets\n",
    "y_train_pred = nn.predict(X_train_scaled)\n",
    "y_test_pred = nn.predict(X_test_scaled)\n",
    "# score the training predictions with r2_score()\n",
    "print(f\"r2_score of y_train: {r2_score(y_train, y_train_pred)}\")\n",
    "# score the test predictions with r2_score()\n",
    "print(f\"r2_score of y_test: {r2_score(y_test, y_test_pred)}\")\n"
   ]
  }
 ]
}