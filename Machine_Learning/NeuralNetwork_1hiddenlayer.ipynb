{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3710jvsc74a57bd0c10d354e963c3ef3cfe26ce7f2c15db051cec7895d853c3c04a448c95c5a7793",
   "display_name": "Python 3.7.10 64-bit ('tf': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "c10d354e963c3ef3cfe26ce7f2c15db051cec7895d853c3c04a448c95c5a7793"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from pandas.api.types import is_string_dtype\n",
    "from pandas.api.types import is_numeric_dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 5340)              14263140  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 5341      \n",
      "=================================================================\n",
      "Total params: 14,268,481\n",
      "Trainable params: 14,268,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 2721 samples\n",
      "Epoch 1/100\n",
      "2721/2721 [==============================] - 10s 3ms/sample - loss: 9309716203127.8613 - mse: 9309717004288.0000\n",
      "Epoch 2/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 9306403852659.8164 - mse: 9306403504128.0000\n",
      "Epoch 3/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 9298416849017.9316 - mse: 9298417549312.0000\n",
      "Epoch 4/100\n",
      "2721/2721 [==============================] - 8s 3ms/sample - loss: 9285442723698.5000 - mse: 9285442469888.0000\n",
      "Epoch 5/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 9267697016786.8398 - mse: 9267698466816.0000\n",
      "Epoch 6/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 9245228779061.6270 - mse: 9245228531712.0000\n",
      "Epoch 7/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 9218696780821.4512 - mse: 9218696413184.0000\n",
      "Epoch 8/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 9187687936814.3828 - mse: 9187686875136.0000\n",
      "Epoch 9/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 9152906382256.5938 - mse: 9152906657792.0000\n",
      "Epoch 10/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 9115059577702.0801 - mse: 9115061452800.0000\n",
      "Epoch 11/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 9074485344855.8730 - mse: 9074484707328.0000\n",
      "Epoch 12/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 9030554017337.3906 - mse: 9030553567232.0000\n",
      "Epoch 13/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 8982990708010.4316 - mse: 8982992257024.0000\n",
      "Epoch 14/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 8933087532252.9062 - mse: 8933087379456.0000\n",
      "Epoch 15/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 8880026862079.8125 - mse: 8880027336704.0000\n",
      "Epoch 16/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 8824293314986.0098 - mse: 8824294473728.0000\n",
      "Epoch 17/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 8766064534139.2490 - mse: 8766065999872.0000\n",
      "Epoch 18/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 8705142727700.6982 - mse: 8705142685696.0000\n",
      "Epoch 19/100\n",
      "2721/2721 [==============================] - 10s 3ms/sample - loss: 8641710446788.4453 - mse: 8641711702016.0000\n",
      "Epoch 20/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 8577210503557.8799 - mse: 8577209073664.0000\n",
      "Epoch 21/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 8510822802615.2744 - mse: 8510823202816.0000\n",
      "Epoch 22/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 8442231472919.8027 - mse: 8442231128064.0000\n",
      "Epoch 23/100\n",
      "2721/2721 [==============================] - 8s 3ms/sample - loss: 8373090591993.5078 - mse: 8373091696640.0000\n",
      "Epoch 24/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 8300011461421.7119 - mse: 8300011716608.0000\n",
      "Epoch 25/100\n",
      "2721/2721 [==============================] - 8s 3ms/sample - loss: 8228788413797.8916 - mse: 8228788240384.0000\n",
      "Epoch 26/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 8155579565085.7295 - mse: 8155579285504.0000\n",
      "Epoch 27/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 8080610005917.7764 - mse: 8080609247232.0000\n",
      "Epoch 28/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 8005050565715.9219 - mse: 8005050957824.0000\n",
      "Epoch 29/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 7927758877167.2539 - mse: 7927757275136.0000\n",
      "Epoch 30/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 7850980089539.8809 - mse: 7850981064704.0000\n",
      "Epoch 31/100\n",
      "2721/2721 [==============================] - 10s 4ms/sample - loss: 7772475311928.5439 - mse: 7772477325312.0000\n",
      "Epoch 32/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 7693973996573.7295 - mse: 7693973585920.0000\n",
      "Epoch 33/100\n",
      "2721/2721 [==============================] - 11s 4ms/sample - loss: 7614457176452.3750 - mse: 7614458494976.0000\n",
      "Epoch 34/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 7534329615725.4180 - mse: 7534328414208.0000\n",
      "Epoch 35/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 7453814780706.3408 - mse: 7453814030336.0000\n",
      "Epoch 36/100\n",
      "2721/2721 [==============================] - 8s 3ms/sample - loss: 7373005215976.5732 - mse: 7373004996608.0000\n",
      "Epoch 37/100\n",
      "2721/2721 [==============================] - 8s 3ms/sample - loss: 7291751291281.1699 - mse: 7291751366656.0000\n",
      "Epoch 38/100\n",
      "2721/2721 [==============================] - 8s 3ms/sample - loss: 7210260462134.7568 - mse: 7210259709952.0000\n",
      "Epoch 39/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 7128070410268.6006 - mse: 7128070225920.0000\n",
      "Epoch 40/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 7046014061988.3633 - mse: 7046015483904.0000\n",
      "Epoch 41/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 6963889510590.4248 - mse: 6963889438720.0000\n",
      "Epoch 42/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 6880295259484.1074 - mse: 6880295911424.0000\n",
      "Epoch 43/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 6798092987025.0752 - mse: 6798092795904.0000\n",
      "Epoch 44/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 6716416223872.5176 - mse: 6716415541248.0000\n",
      "Epoch 45/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 6635050807526.3164 - mse: 6635051286528.0000\n",
      "Epoch 46/100\n",
      "2721/2721 [==============================] - 8s 3ms/sample - loss: 6553815191466.1963 - mse: 6553814958080.0000\n",
      "Epoch 47/100\n",
      "2721/2721 [==============================] - 8s 3ms/sample - loss: 6472362489254.6211 - mse: 6472361574400.0000\n",
      "Epoch 48/100\n",
      "2721/2721 [==============================] - 8s 3ms/sample - loss: 6390166513208.6377 - mse: 6390166323200.0000\n",
      "Epoch 49/100\n",
      "2721/2721 [==============================] - 8s 3ms/sample - loss: 6310329583013.1162 - mse: 6310330368000.0000\n",
      "Epoch 50/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 6230020574562.1289 - mse: 6230020456448.0000\n",
      "Epoch 51/100\n",
      "2721/2721 [==============================] - 8s 3ms/sample - loss: 6151065321658.6602 - mse: 6151065829376.0000\n",
      "Epoch 52/100\n",
      "2721/2721 [==============================] - 8s 3ms/sample - loss: 6068732924926.1182 - mse: 6068733214720.0000\n",
      "Epoch 53/100\n",
      "2721/2721 [==============================] - 8s 3ms/sample - loss: 5993317152558.0068 - mse: 5993317007360.0000\n",
      "Epoch 54/100\n",
      "2721/2721 [==============================] - 8s 3ms/sample - loss: 5919857018987.6309 - mse: 5919856918528.0000\n",
      "Epoch 55/100\n",
      "2721/2721 [==============================] - 8s 3ms/sample - loss: 5847079048479.1416 - mse: 5847077879808.0000\n",
      "Epoch 56/100\n",
      "2721/2721 [==============================] - 8s 3ms/sample - loss: 5774878000717.7129 - mse: 5774878703616.0000\n",
      "Epoch 57/100\n",
      "2721/2721 [==============================] - 8s 3ms/sample - loss: 5702515495271.7734 - mse: 5702515949568.0000\n",
      "Epoch 58/100\n",
      "2721/2721 [==============================] - 8s 3ms/sample - loss: 5631535167856.0527 - mse: 5631536267264.0000\n",
      "Epoch 59/100\n",
      "2721/2721 [==============================] - 8s 3ms/sample - loss: 5560420278822.9502 - mse: 5560419745792.0000\n",
      "Epoch 60/100\n",
      "2721/2721 [==============================] - 8s 3ms/sample - loss: 5490622201904.1709 - mse: 5490623381504.0000\n",
      "Epoch 61/100\n",
      "2721/2721 [==============================] - 8s 3ms/sample - loss: 5419954509336.2734 - mse: 5419955126272.0000\n",
      "Epoch 62/100\n",
      "2721/2721 [==============================] - 8s 3ms/sample - loss: 5351629210870.4971 - mse: 5351629389824.0000\n",
      "Epoch 63/100\n",
      "2721/2721 [==============================] - 8s 3ms/sample - loss: 5284335642144.5527 - mse: 5284334403584.0000\n",
      "Epoch 64/100\n",
      "2721/2721 [==============================] - 8s 3ms/sample - loss: 5214420593087.8350 - mse: 5214420074496.0000\n",
      "Epoch 65/100\n",
      "2721/2721 [==============================] - 8s 3ms/sample - loss: 5149671398036.0869 - mse: 5149671555072.0000\n",
      "Epoch 66/100\n",
      "2721/2721 [==============================] - 8s 3ms/sample - loss: 5084463526046.0596 - mse: 5084465332224.0000\n",
      "Epoch 67/100\n",
      "2721/2721 [==============================] - 8s 3ms/sample - loss: 5022481906489.6729 - mse: 5022483480576.0000\n",
      "Epoch 68/100\n",
      "2721/2721 [==============================] - 8s 3ms/sample - loss: 4961201929138.0996 - mse: 4961202077696.0000\n",
      "Epoch 69/100\n",
      "2721/2721 [==============================] - 8s 3ms/sample - loss: 4901384570969.5674 - mse: 4901385011200.0000\n",
      "Epoch 70/100\n",
      "2721/2721 [==============================] - 8s 3ms/sample - loss: 4842482734343.0566 - mse: 4842483875840.0000\n",
      "Epoch 71/100\n",
      "2721/2721 [==============================] - 8s 3ms/sample - loss: 4783752785740.8652 - mse: 4783753134080.0000\n",
      "Epoch 72/100\n",
      "2721/2721 [==============================] - 8s 3ms/sample - loss: 4726698280453.4570 - mse: 4726698541056.0000\n",
      "Epoch 73/100\n",
      "2721/2721 [==============================] - 8s 3ms/sample - loss: 4670659903168.8701 - mse: 4670659493888.0000\n",
      "Epoch 74/100\n",
      "2721/2721 [==============================] - 8s 3ms/sample - loss: 4615800394533.3516 - mse: 4615800619008.0000\n",
      "Epoch 75/100\n",
      "2721/2721 [==============================] - 8s 3ms/sample - loss: 4558916462503.9385 - mse: 4558916419584.0000\n",
      "Epoch 76/100\n",
      "2721/2721 [==============================] - 8s 3ms/sample - loss: 4506854152942.4062 - mse: 4506853048320.0000\n",
      "Epoch 77/100\n",
      "2721/2721 [==============================] - 8s 3ms/sample - loss: 4456260581972.8623 - mse: 4456261877760.0000\n",
      "Epoch 78/100\n",
      "2721/2721 [==============================] - 8s 3ms/sample - loss: 4405078025917.1074 - mse: 4405078261760.0000\n",
      "Epoch 79/100\n",
      "2721/2721 [==============================] - 8s 3ms/sample - loss: 4353644456335.6650 - mse: 4353645084672.0000\n",
      "Epoch 80/100\n",
      "2721/2721 [==============================] - 8s 3ms/sample - loss: 4306885137592.7788 - mse: 4306886197248.0000\n",
      "Epoch 81/100\n",
      "2721/2721 [==============================] - 8s 3ms/sample - loss: 4259769813713.8052 - mse: 4259770269696.0000\n",
      "Epoch 82/100\n",
      "2721/2721 [==============================] - 8s 3ms/sample - loss: 4215691666422.5913 - mse: 4215692328960.0000\n",
      "Epoch 83/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 4171304935131.9663 - mse: 4171303485440.0000\n",
      "Epoch 84/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 4129515252987.7661 - mse: 4129515896832.0000\n",
      "Epoch 85/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 4088467467019.0083 - mse: 4088467030016.0000\n",
      "Epoch 86/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 4045047681522.2637 - mse: 4045047595008.0000\n",
      "Epoch 87/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 4007032826888.2793 - mse: 4007032782848.0000\n",
      "Epoch 88/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 3969977764917.0630 - mse: 3969977417728.0000\n",
      "Epoch 89/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 3933685175845.8213 - mse: 3933684891648.0000\n",
      "Epoch 90/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 3898247241411.8809 - mse: 3898246692864.0000\n",
      "Epoch 91/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 3864053575043.2461 - mse: 3864053415936.0000\n",
      "Epoch 92/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 3830803296119.0156 - mse: 3830803333120.0000\n",
      "Epoch 93/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 3797915076077.3716 - mse: 3797914484736.0000\n",
      "Epoch 94/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 3762760753787.2490 - mse: 3762760712192.0000\n",
      "Epoch 95/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 3732841991263.2124 - mse: 3732842741760.0000\n",
      "Epoch 96/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 3704550180724.7568 - mse: 3704550850560.0000\n",
      "Epoch 97/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 3676662595126.3799 - mse: 3676662398976.0000\n",
      "Epoch 98/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 3649525623779.7754 - mse: 3649525776384.0000\n",
      "Epoch 99/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 3623024556598.7559 - mse: 3623024590848.0000\n",
      "Epoch 100/100\n",
      "2721/2721 [==============================] - 9s 3ms/sample - loss: 3596063652171.9253 - mse: 3596062818304.0000\n",
      "r2_score of y_train: 0.18583694384115557\n",
      "r2_score of y_test: 0.17580814322504268\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('senate_dataset.csv')\n",
    "#Create category_columns and numeric_columns variables\n",
    "numeric_columns = []\n",
    "category_columns = []\n",
    "for col in df.columns:\n",
    "    if is_string_dtype(df[col]) == True:\n",
    "        category_columns.append(col)\n",
    "    elif is_numeric_dtype(df[col]) == True:\n",
    "        numeric_columns.append(col)\n",
    "#Create dummy variables for the category_columns and merge on the numeric_columns to create an X dataset\n",
    "category_columns = pd.get_dummies(df[category_columns])\n",
    "X = df[numeric_columns].merge(category_columns, left_index= True, right_index= True)\n",
    "#Create an y dataset\n",
    "y = df['totalvotes'].values\n",
    "# Split X and y into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "# Scale X_train and X_test\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.fit_transform(X_test)\n",
    "\n",
    "# Create a neural network model with keras\n",
    "nn = tf.keras.models.Sequential()\n",
    "# Add a hidden layer with twice as many neurons as there are inputs. Use 'relu'\n",
    "n_input = len(X_train_scaled[0])\n",
    "\n",
    "n_hidden = n_input * 2\n",
    "#n_hidden_layer2 = n_input * 2 #2nd hidden layer\n",
    "\n",
    "nn.add(tf.keras.layers.Dense(units=n_hidden, input_dim=n_input, activation='relu'))\n",
    "#nn.add(tf.keras.layers.Dense(units=n_hidden_layer2, activation='relu')) #2nd hidden layer\n",
    "\n",
    "# add an output layer with a 'linear' activation function.\n",
    "nn.add(tf.keras.layers.Dense(units=1,  activation='linear'))\n",
    "# print a summary of the model\n",
    "print(nn.summary())\n",
    "# compile the model using the \"adam\" optimizer and \"mean_squared_error\" loss function\n",
    "nn.compile(loss='mean_squared_error' , optimizer='adam' , metrics=['mse'])\n",
    "# train the model for 100 epochs\n",
    "model = nn.fit(X_train_scaled, y_train, epochs=100)\n",
    "# predict values for the train and test sets\n",
    "y_train_pred = nn.predict(X_train_scaled)\n",
    "y_test_pred = nn.predict(X_test_scaled)\n",
    "# score the training predictions with r2_score()\n",
    "print(f\"r2_score of y_train: {r2_score(y_train, y_train_pred)}\")\n",
    "# score the test predictions with r2_score()\n",
    "print(f\"r2_score of y_test: {r2_score(y_test, y_test_pred)}\")"
   ]
  }
 ]
}